<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Sam Nolan" />
  <meta name="dcterms.date" content="2021-10-28" />
  <title>A Living Review on the Usability of Interactive Theorem Provers</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="pandoc.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script defer src="src/bundle.js"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">A Living Review on the Usability of Interactive Theorem Provers</h1>
<div class="header-logo">
<img src="Images/rmit-logo.png" width="300px" />
</div>
<p class="author">Sam Nolan</p>
<p class="date">28 October 2021</p>
</header>

<h2>Declaration</h2>
<p>
I certify that except where due acknowledgment has been made, the work is that of the author alone; the work has not been submitted previously, in whole or in part, to qualify for any other academic award; the content of the thesis is the result of work which has been carried out since the official commencement date of the approved research program; any editorial work, paid or unpaid, carried out by a third party is acknowledged; and, ethics procedures and guidelines have been followed.<br />
Signed: Sam Nolan<br />
Date: 28 October 2021<br />
</p>

<h2>Abstract</h2>
<p>Interactive Theorem Provers (ITPs) are tools that allows a user to both prove mathematical theorems, and also verify correctness properties of systems. Through proving sotware correct, ITPs reduce the amount of errors and give a high level of assurance of correctness. However, although the field is growing, the adoption of ITPs in mathematics and software development is far from widespread. It’s been suggested that the reason for this is that ITPs are particulary difficult to use, and this could be a major reason why there is not a larger adoption of ITPs. This thesis attempts to uncover possible usability issues through a systematic literature review, and finds that the field is greatly lacking in empirical research. This thesis then contributes an in depth investigation to three usability issues, small mathematical scopes of ITPs support for counterexample generators, and math notation support. The results are presented in a living review, which updates semi-automatically to reflect the current state of the field. The living review doubles as a decision making tool for mathematicians, as some ITPs are better for different fields of mathematics, and tracks progress towards resolving this issue. Due to the updating nature of this review, a copy of this thesis can be found in html form at https://samnolan.me/thesis.</p>

<nav id="TOC" role="doc-toc">
<h2 id="toc-title">Table of Contents</h2>
<ul>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#formal-methods">Formal Methods</a></li>
<li><a href="#sec:interaction_paradigms">ITP Interaction Paradigms</a></li>
<li><a href="#sec:using_an_itp">Using an ITP</a></li>
<li><a href="#cognitive-dimensions">Cognitive Dimensions</a></li>
<li><a href="#research-questions">Research Questions</a></li>
</ul></li>
<li><a href="#methodology">Methodology</a>
<ul>
<li><a href="#sec:review_methodology">Systematic Literature Review Methodology</a></li>
<li><a href="#sec:living_review_meth">Living Review Methodology</a>
<ul>
<li><a href="#sec:chosing_itps">Choosing Interactive Theorem Provers to Cover</a></li>
<li><a href="#sec:scope_of_library_meth">Scope of Library</a></li>
<li><a href="#sec:counterexample_meth">Counterexample Generator Methodology</a></li>
<li><a href="#sec:math_notation_meth">Math Notation Methodology</a></li>
<li><a href="#general-features-of-about-itps">General features of about ITPs</a></li>
</ul></li>
</ul></li>
<li><a href="#sec:literature_review">Literature Review</a>
<ul>
<li><a href="#theorem-provers">Theorem Provers</a></li>
<li><a href="#abstraction-gradient">Abstraction Gradient</a></li>
<li><a href="#closeness-of-mapping">Closeness of Mapping</a></li>
<li><a href="#consistency">Consistency</a></li>
<li><a href="#diffuseness-terseness">Diffuseness / Terseness</a></li>
<li><a href="#error-proneness">Error Proneness</a></li>
<li><a href="#hard-mental-operations">Hard Mental Operations</a></li>
<li><a href="#hidden-dependencies">Hidden Dependencies</a></li>
<li><a href="#perceptual-cues">Perceptual Cues</a></li>
<li><a href="#premature-commitment">Premature Commitment</a></li>
<li><a href="#progressive-evaluation">Progressive Evaluation</a></li>
<li><a href="#secondary-notation">Secondary Notation</a></li>
<li><a href="#viscosity">Viscosity</a></li>
<li><a href="#visibility">Visibility</a></li>
<li><a href="#analysis">Analysis</a></li>
</ul></li>
<li><a href="#sec:results">Results</a>
<ul>
<li><a href="#sec:math_libraries">Mathematical Libraries</a>
<ul>
<li><a href="#step-1-identifying-libraries">Step 1: Identifying Libraries</a></li>
<li><a href="#step-2-collecting-modules">Step 2: Collecting modules</a></li>
<li><a href="#step-3-classifying-modules">Step 3: Classifying modules</a></li>
</ul></li>
<li><a href="#sec:counterexamples">Counterexample generators</a></li>
<li><a href="#sec:math_notation">Math Notation in libraries</a></li>
</ul></li>
<li><a href="#discussion">Discussion</a>
<ul>
<li><a href="#limitations-with-current-work">Limitations with current work</a></li>
<li><a href="#future-work">Future Work</a></li>
<li><a href="#summary">Summary</a></li>
</ul></li>
<li><a href="#bibliography">Bibliography</a></li>
</ul>
</nav>
<h1 id="introduction">Introduction</h1>
<p>This is a thesis about <strong>Interactive Theorem Provers</strong>, what they are, why they might be difficult to use, and whether you should explore using them in your next project.</p>
<p>An <strong>Interactive Theorem Prover</strong> (ITP) or <strong>Proof Assistant</strong> is a piece of software that helps a user prove mathematical theorems, or equivalently, prove correctness properties about software. Some of the more well known examples of ITPs include <a href="https://coq.inria.fr/">Coq</a> and <a href="https://isabelle.in.tum.de/">Isabelle</a>.</p>
<p>An ITP is often used by either a mathematician or an engineer. From the side of a mathematician, ITPs allow users to specify a proposition that they would like to prove, and then specify to the ITP how to construct that proof of the proposition. The ITP can then check whether the given proof is valid. Usually, when a proof in mathematics is made, it must be checked for errors before being accepted. The use of an ITP automates this verification, and means that the mathematician only needs to trust that the ITP was implemented correctly in order to trust any proof that’s been created from it. By formalizing mathematics within ITPs, mathematicians can create libraries of formal trustworthy proofs. This allows computers to aid with the proof process, and helps improve the trustworthiness of proofs.</p>
<p>ITPs have been used for formalizing mathematics in the past. For instance, the QED Manifesto <span class="citation" data-cites="QED_Manifesto">[<a href="#ref-QED_Manifesto" role="doc-biblioref">85</a>]</span> has proposed using ITPs to generate computer checkable proofs for mathematics. Further, they have been used to prove theorems such as the four colour theorem in Coq <span class="citation" data-cites="Four_Color">[<a href="#ref-Four_Color" role="doc-biblioref">32</a>]</span> and the Kepler Conjecture in a mixture of HOL Light and Isabelle <span class="citation" data-cites="Flyspeck">[<a href="#ref-Flyspeck" role="doc-biblioref">40</a>]</span>.</p>
<p>An ITP can however also be used by a software engineer to create <strong>certified software</strong>. <strong>Certified software</strong> is software that’s been proven to operate correctly, meaning that software is proven to operate as according to the specification. When developing software, eradicating bugs is usually done through procedures such as code reviews or software testing. However, these will often not identify 100% of the errors. ITPs allow you to prove that the implementation matches the specification 100%. Proving the software correct can give the assurance that the software implementation matches the specification. This is a very high level of assurance in terms of quality, and dramatically reduces the sources of errors in software. ITPs have been used to ensure correctness of code bases that require a large amount of trust, such as cryptographic libraries <span class="citation" data-cites="HACL">[<a href="#ref-HACL" role="doc-biblioref">47</a>]</span>, microkernels <span class="citation" data-cites="Sel4">[<a href="#ref-Sel4" role="doc-biblioref">53</a>]</span> and compilers <span class="citation" data-cites="CompCert">[<a href="#ref-CompCert" role="doc-biblioref">54</a>]</span>.</p>
<p>In computer science, often correctness proofs of algorithms (For example, Dijkstra’s algorithm <span class="citation" data-cites="DijkstraACL2">[<a href="#ref-DijkstraACL2" role="doc-biblioref">60</a>]</span> in an undergraduate context) are described and proved to be correct on pen and paper. The use of an ITP is analogous to this type of activity. Except that an ITP aids the user in developing the proof, offering hints and/or automating portions of the proof along the way.</p>
<p>The task of creating verified software is split into two steps: first specification and then verification.</p>
<p>During specification, the user specifies what it is that they would like to prove, for example, that Dijkstra’s algorithm always finds the shortest path between one node and all other nodes in a weighted graph, assuming positive weights. In this step, the user would create a specification for what is Dijkstra’s algorithm, graphs, and shortest paths. Then state that Dijkstra’s algorithm finds the shortest path. This step is far from trivial, as developing a precise form of specification for software requires having a detailed understanding of how exactly you want it to work. Often within the verification process, a user might realise that the specification itself is in error in some way, and might go back to correct the specification during the process.</p>
<p>This specification leaves the user with a <strong>proof obligation</strong>. A proof obligation is a onus on the user to prove that the specification of the software is correct. Then, during verification, it is then up to the user to provide to the ITP the reasoning as to why this proposition is correct. This can be done in several ways, sometimes through the use of automated software, or manipulating the proof by pointing and clicking, or writing down a <strong>proof script</strong> that describes the steps made to prove the theorem. Often this involves breaking down one proof obligation into many other simpler proof obligations that can be solved individually.</p>
<p>The user and the ITP work together until they have specified a proof of the statement they wish to claim. This is an iterative process where the user may specify what they want to prove, then attempt to prove the proposition, find out the proposition or the specification that they are proving has a typo or error, fix the specification, continue developing the proof, realise the approach of the proof won’t work, backtrack and start from an earlier state, realise they need to prove some auxiliary lemma, create the lemma and prove that, come back to the original proof etc. The ITP helps the user in the process by providing counterexamples for propositions that may be incorrectly specified, automatically solving some components of the proof, offering libraries of mathematical results and informing the user of any errors in the reasoning of the proof. Once that proof is made, assuming the ITP is functioning correctly and the specification is correct, the user can be assured that the proposition is true.</p>
<p>ITPs are often implemented by making use of a programming language, particularly statically typed functional programming languages. A functional programming language is a language that creates problems from the composition and definition of functions, such as Haskell or OCaml. Often a goal in creating statically typed functional programming languages is to create languages where its difficult or impossible to make a certain class of errors. For instance, Rust <span class="citation" data-cites="Rust">[<a href="#ref-Rust" role="doc-biblioref">57</a>]</span> is designed to allow systems level programming that’s protected from memory errors, and Elm <span class="citation" data-cites="Elm">[<a href="#ref-Elm" role="doc-biblioref">27</a>]</span> is designed to create web programs that do not have runtime errors. This means that possible software implementation errors are caught as they are being typed checked, very early in the development process. ITPs can also be seen as an extension of this by having type systems and features that allow the user to go as far as proving arbitrary correctness properties about the software.</p>
<p>More widespread use of ITPs is valuable as it allows for errors to be caught much earlier in the development process. ITPs allow for errors in specification or implementation to be found as the software as the software is being developed. This prevents errors from arising when testing or even worse, in production software. Such errors can be much more expensive to fix <span class="citation" data-cites="CodeComplete">[<a href="#ref-CodeComplete" role="doc-biblioref">58</a>]</span>.</p>
<h2 id="formal-methods">Formal Methods</h2>
<p>ITPs are not the only way to specify and verify software. They belong to a class of techniques named <strong>Formal Methods</strong>.</p>
<p>In essence, formal methods attempts to improve the process that users can prove the correctness of their software systems. Use of formal methods can be done without any tools at all, by simply proving properties manually, with paper and pencil, such as the Dijkstra example above <span class="citation" data-cites="Dijkstra">[<a href="#ref-Dijkstra" role="doc-biblioref">1</a>]</span>.</p>
<p>However, when proving the correctness of larger systems, proving properties by hand quickly becomes intractable. Computers and tools have aided people in providing larger correction proofs for software systems. The tools used in Formal Methods can be roughly divided into three categories, Model Checkers, Automated Theorem Provers and Interactive Theorem Provers.</p>
<p>These three techniques are a trade off in three features. You can pick two but not all three.</p>
<figure>
<img src="./Images/formalmethods.png" id="fig:formal_methods" alt="Figure 1: Three categories of Formal Methods" /><figcaption aria-hidden="true">Figure 1: Three categories of Formal Methods</figcaption>
</figure>
<p><strong>Features of Formal Methods Tools:</strong></p>
<p><strong>Automation</strong>: Whether finding a proof is fully automated. That is, the user does not need to specify a proof manually for the proposition, the system simply attempts to find one automatically.</p>
<p><strong>Termination</strong>: Whether the tool terminates in a practical amount of time when attempting to find a proof. For instance, does not have the possibility of running for several days when attempting to prove a proposition.</p>
<p><strong>Scope</strong>: Whether the tool is able to prove any arbitrary property about a system. The properties that can be proven are not restricted to a subset of possible properties.</p>
<p><strong>Formal Methods Tools:</strong></p>
<p><strong>Model Checkers</strong> are fully automated and if the specification is not particularly large, can find solutions in a reasonable amount of time. However, Model checkers can do this by restricting the scope of the systems that they can prove. They allow for a specification for a system in a (usually finite) state machine or automaton, and can prove properties about this state machine. This means that you can only prove with a model checker some simplification of the actual system, and often cannot prove more complicated properties such as those with numbers. This means that not all properties about the system can be verified.</p>
<p><strong>Automated Theorem Provers</strong> (ATPs) are fully automated and can prove arbitrary theorems, however may not terminate in reasonable time. For larger systems or more complicated theorems, they may run forever and never identify a proof or disproof for the proposition.</p>
<p><strong>Interactive Theorem Provers</strong> terminate in reasonable time and can prove arbitrary theorems. However, they are not fully automated, and require the user’s input to guide the proof of the theorem. This is a major limitation as interacting with a human is often relatively slow and expensive. Especially if the propositions that are being proven are more trivial and could be solved quickly with an ATP.</p>
<p>The distinction between ATPs and ITPs is however not clear cut. ATPs can often include minor user interaction in order to correct it’s path and find a proof. And ITPs often have automatic features and can even call external ATPs to help automatically prove goals.</p>
<p>ITPs were chosen for this investigation due their usage in creating fully certified software <span class="citation" data-cites="CertifiedSoftware">[<a href="#ref-CertifiedSoftware" role="doc-biblioref">77</a>]</span>. Model checkers can be used to check important properties about software, but can’t get the last mile to make it fully certified due to not allowing the user to prove all the propositions that might be relevant to the code. As reliance on technology is only getting greater, it’s important to consider making technology as trustworthy as possible, particularly if the software is safety/security-critical.</p>
<p>That being said, ATPs are often used beside ITPs, where an ITP might call an ATP to prove a proposition or discover a counterexample automatically. The primary goal in the development of ATPs is the speed at which it can prove a variety of theorems. As of such, development of ATPs directly influences development of ITPs by improving some of the automation related tools in ITPs.</p>
<h2 id="sec:interaction_paradigms">ITP Interaction Paradigms</h2>
<p>ITPs can go about proving and specifying properties about software in different ways. This section outlines a short history of interaction paradigms with ITPs, and possible developments.</p>
<p>Direct Manipulation ITPs such as KeY work by editing proof objects until the obligations have been resolved. These provers often have issues with tedious interactions, and work has even been done add textual elements to KeY <span class="citation" data-cites="beckert_interaction_2017">[<a href="#ref-beckert_interaction_2017" role="doc-biblioref">16</a>]</span>. The development of interfaces to Direct Manipulation provers often differs from textual ones.</p>
<p>Textual ITPs such as HOL, Isabelle, Coq and Matita work by writing a proof script that attempts to prove a proposition. Interacting with textual ITPs often involves a very simple read-evaluate-print-loop (REPL) for their interfaces. This is very similar to the example we went through in section Section <a href="#sec:using_an_itp">1.3</a>. One very stark example of this is HOL-Light, which the user interacts with by opening up the OCaml REPL (a general purpose ML based functional programming language) and loading the HOL library. All OCaml is available alongside the HOL library. Although this is rather primitive, modern ITP interfaces such as Isabelle/jEdit and CoqIDE usually offer only a small layer of abstraction over a REPL for their own languages.</p>
<p>These interfaces have two main windows, the first has code and the second has proof state. The code can be evaluated up to a certain point, and the output from the REPL in terms of proof state are printed in the second window. The only major difference between this and a standard REPL is that the user can rewind to evaluate up to a previous line. This simple style of interface has consequences for usability. In particular, if any error is found either in proof or in syntax, execution stops until that error is resolved. Further, for larger projects, it can take a very long time for systems to recompile. It also means that the user can only reference things that have already been declared (it has to be a single pass). This is particularly an issue when automated tactics attempt to use lemmas above them to find solutions to theorems (such as Isabelle). This means that simply changing the order of lemmas in an Isabelle document, even if they never reference lemmas that are below them, could cause a lemma that was proven before to become unproven.</p>
<p>Developments in IDEs to allow asynchronous interfaces, reloading only parts needed and loading proofs out of order have been introduces to fix this problem. They are called "Prover IDEs", with two examples being Isabelle/PIDE <span class="citation" data-cites="wenzel_asynchronous_2014">[<a href="#ref-wenzel_asynchronous_2014" role="doc-biblioref">82</a>]</span> and Coq/PIDE <span class="citation" data-cites="barras_asynchronous_2015">[<a href="#ref-barras_asynchronous_2015" role="doc-biblioref">10</a>]</span>. These hopefully will resolve some of the issues cited above.</p>
<p>Although we have examples of large projects undertaken with ITPs, optimal interaction paradigms are still up for debate, and several novel interaction paradigms have surfaced. Including proving theorems and writing tactics with diagrams <span class="citation" data-cites="grov_tinker_2018 lin_understanding_2016 shams_accessible_2018">[<a href="#ref-grov_tinker_2018" role="doc-biblioref">38</a>, <a href="#ref-lin_understanding_2016" role="doc-biblioref">55</a>, <a href="#ref-shams_accessible_2018" role="doc-biblioref">76</a>]</span>, or providing agent based interfaces <span class="citation" data-cites="hunter_agent-based_2005">[<a href="#ref-hunter_agent-based_2005" role="doc-biblioref">46</a>]</span>.</p>
<p>We now move into the usability problems and solutions found in ITPs.</p>
<h2 id="sec:using_an_itp">Using an ITP</h2>
<p>To explain the typical terms and issues related to ITPs, let us present an small toy example of using an ITP using pseudocode syntax.</p>
<p>Our pseudocode syntax is based on textual ITPs such as Isabelle, Coq and HOL. The syntax is simplified to get the basic concepts of ITPs across without too many of the technical details.</p>
<p>To prove a property with an ITP, the user must start by having a goal that they wish to prove. You then manipulate and decompose that goal into simpler subgoals, until they’ve proven the proposition they wish to prove.</p>
<p>We start with a function:</p>
<p><span class="math display">\[
f(x) = 
  \begin{cases}
    f(x - 1) + x, &amp; x &gt; 0 \\
    0, &amp; x = 0
  \end{cases}
\]</span></p>
<p>This is the triangle number function. It adds a number to every number below that number up until 0. For instance, <span class="math inline">\(f(5) = 5 + 4 + 3 + 2 + 1 + 0 = 15\)</span>.</p>
<p>However, there is a quicker way to calculate the triangle number, and that is that is that <span class="math inline">\(f(x) = \frac{x(x + 1)}{2}\)</span>.</p>
<p>This proof is an elementary induction proof. But we shall demonstrate that this statement is true.</p>
<p>We would like to prove that:</p>
<p><span class="math display">\[ f(x) = \frac{x(x + 1)}{2} \]</span></p>
<p>Textual ITPs are similar to interactive programming languages, such as R and Bash, where the main interaction is through a Read Evaluate Print Loop or REPL. You start by writing a line of code, and the ITP will return the state. These lines of code manipulate the state until the statement has been prover. After the proof, the user is left with a proof script, which is a listing of all the code used to prove the proposition.</p>
<p>To start with our proof, we first have to specify the property that we wish to prove. In pseudocode, we write Listing <a href="#lst:proposition">1</a> into our ITP. This statement says that the user would like to <code>Prove</code> the statement <code>forall x, f(x) = x * (x + 1) / 2</code>. <code>Prove</code> here is a keyword that starts the proof. Everything between the <code>:</code> and the <code>.</code> represent the statement they wish to prove.</p>
<div id="lst:proposition" class="listing">
<p>Listing 1: User Input: Statement of the proposition to prove</p>
<pre><code>Prove: forall x, f(x) = x * (x + 1) / 2.</code></pre>
</div>
<p>After writing this statement, the ITP will print the display shown in Listing <a href="#lst:starting_state">2</a>. This will often appear in a window in the ITP interface, or if it is a command line prover, it will print it to console.</p>
<p>The state is separated into two sections, everything above the <code>---</code> is an assumption, that is, what we have assumed to be true. We can have multiple assumptions, but in this case, there are none. Then the statement below the <code>---</code> is the <strong>goal</strong>. This is the statement to prove. When starting a proof, whatever statement the user wishes to prove becomes the first goal, but both the assumptions and the goal will change as the user progress in the proof. It’s also possible to split the goal into multiple subgoals as the proof is being developed.</p>
<div id="lst:starting_state" class="listing">
<p>Listing 2: ITP Output: Starting state</p>
<pre><code>          
---
forall x, f(x) = x * (x + 1) / 2</code></pre>
</div>
<p>Now we must give a series of <strong>tactics</strong> to the ITP to prove this proposition. A tactic is like a command that is sent to the ITP in order to prove the proposition that you wish to prove. Tactics are always typed, and sometimes they fail to work in situations where their usage would be invalid. These tactics form a language that you can use to specify your proof.</p>
<p>It should be noted that while attempting to prove a proposition, the user may wish to attempt to prove a goal or subgoal automatically. Most ITPs have the ability to automatically prove simple propositions, often by giving the <code>auto</code> tactic to the prover. If this succeeds, then the user is done and the proposition is proven. Otherwise, the user must continue to explore proof options. Furthermore, the ITP can assist the user by offering counterexamples to why the proposition might not actually be true. We will assume that the statement cannot be proven automatically.</p>
<p>This particular proof is often used as an introductory induction proof, so induction would be a good start to solving this. Entering the pseudocode in Listing <a href="#lst:induction_tactic">3</a> performs induction on the variable x. To perform induction, we must prove the base case, and then prove the inductive case. The ITP will ask to prove them one at a time, starting with the base case. After the tactic is executed, the state of the ITP will be modified, and display the state in Listing <a href="#lst:induction_state">4</a>.</p>
<p>The state has now been split up into two <em>subgoals</em>. One for the base case and one for the induction case, which is labeled as (1/2). In our pseudocode ITP, all the tactics that we write will manipulate the first goal only, but the ITP is indicating that there still is a second goal that needs to be proven after this first one. This means that the theorem prover is asking for a proof of the base case, that is, that the statement is true when <span class="math inline">\(x = 0\)</span>.</p>
<div id="lst:induction_tactic" class="listing">
<p>Listing 3: Running the induction tactic</p>
<pre><code>induction x</code></pre>
</div>
<div id="lst:induction_state" class="listing">
<p>Listing 4: State after the induction tactic</p>
<pre><code>          
---
f(0) = 0 * (0 + 1) / 2
(1/2)
---
f(x) = x * (x + 1) / 2 -&gt; f(x + 1) = (x + 1) * (x + 2) / 2
(2/2)</code></pre>
</div>
<p>Notice that the tactic modifies the state of the ITP. Only tactics that are valid at the time are allowed to be used, ensuring that all proof steps are valid and construct a correct proof.</p>
<p>The base case is very easy to solve, as simply evaluating the function on both sides (<span class="math inline">\(f(0) = 0\)</span> and <span class="math inline">\(\frac {0 \cdot (0 + 1)}{2} = 0\)</span>) gives 0.</p>
<p>To evaluate this, we use the <code>simplify</code> tactic in Listing <a href="#lst:simplify_tactic">5</a>. This tactic attempts to try a list of rules that the prover guesses will simplify the current statement. In our pseudocode ITP, this includes evaluating statements with constants. The result is as we expect and shown in Listing <a href="#lst:simplify_state">6</a>. Indicating that after the simplification, both sides are equal to each other.</p>
<div id="lst:simplify_tactic" class="listing">
<p>Listing 5: Running the simplify tactic</p>
<pre><code>simplify</code></pre>
</div>
<div id="lst:simplify_state" class="listing">
<p>Listing 6: State after running the simplify tactic</p>
<pre><code>          
---
0=0
(1/2)
---
f(x) = x * (x + 1) / 2 -&gt; f(x + 1) = (x + 1) * (x + 2) / 2
(2/2)
---</code></pre>
</div>
<p>Now the goal is to prove that <code>0=0</code>. This is trivially true because equality is reflexive. As of such, we can prove the current goal by indicating that it’s reflexive. We can use the <code>reflexivity</code> tactic to prove any goal that is true because of reflexivity. This tactic is executed in Listing <a href="#lst:reflexivity_tactic">7</a>.</p>
<p>After we have solved the first goal, the base case, the pseudo-ITP is now asking us to prove the inductive case in Listing <a href="#lst:reflexivity_state">8</a>. The current goal is now to prove the inductive case. As it is with induction, the inductive case allows us to assume that the original proposition is true for any x, and that we need to prove that it is the case for x + 1. Therefore, the statement for proposition for (x + 1) is our goal.</p>
<div id="lst:reflexivity_tactic" class="listing">
<p>Listing 7: Running the reflexivity tactic</p>
<pre><code>reflexivity</code></pre>
</div>
<div id="lst:reflexivity_state" class="listing">
<p>Listing 8: State after running the reflexivity tactic</p>
<pre><code>f(x) = x * (x + 1) / 2
---
f(x + 1) = (x + 1) * (x + 2) / 2</code></pre>
</div>
<p>The first step would be to replace <code>f(x + 1)</code> with it’s definition. This can be done with the <code>unfold</code> tactic, as shown in Listing <a href="#lst:unfold_tactic">9</a>. This tactic replaces a function with it’s definition. This replacement is shown in Listing <a href="#lst:unfold_state">10</a></p>
<div id="lst:unfold_tactic" class="listing">
<p>Listing 9: Running the unfold tactic</p>
<pre><code>unfold f</code></pre>
</div>
<div id="lst:unfold_state" class="listing">
<p>Listing 10: State after running the reflexivity tactic</p>
<pre><code>f(x) = x * (x + 1) / 2
---
f(x) + (x + 1) = (x + 1) * (x + 2) / 2</code></pre>
</div>
<p>Our current assumption and the goal are equivalent statements in different forms. We now have to re-arrange the goal to make it equal to the assumption. This might involve several tactics to manipulate the state of the equation. We will for the sake of brevity written these tactics in English like code in Listing <a href="#lst:rearangement_tactics">11</a>. The intermediate goals are shown in Listing <a href="#lst:intermediate_states">12</a> to show the progress towards the desired goal, and the final state is shown in Listing <a href="#lst:rearangement_state">13</a>.</p>
<div id="lst:rearangement_tactics" class="listing">
<p>Listing 11: Running re-arangement tactics</p>
<pre><code>expand (x + 1) * (x + 2)
subtract both sides (x + 1)
replace (x + 1) with (2 * (x + 1) / 2)
combine fraction
simplify
factorise (x * x - x)</code></pre>
</div>
<div id="lst:intermediate_states" class="listing">
<p>Listing 12: States after running each tactic</p>
<pre><code>f(x) + (x + 1) = (x^2 + 3x + 2) / 2
f(x) = (x^2 + 3x + 2) / 2 - (x + 1)
f(x) = (x^2 x + 3x + 2) / 2 - ( 2 * (x + 1) / 2)
f(x) = (x^2 + 3x + 2 - 2 * (x + 1)) / 2
f(x) = (x^2 + x) / 2
f(x) = x * (x + 1) / 2</code></pre>
</div>
<div id="lst:rearangement_state" class="listing">
<p>Listing 13: Final state after running each tactic</p>
<pre><code>f(x) = x * (x + 1) / 2
---
f(x) = x * (x + 1) / 2</code></pre>
</div>
<p>Because we know the inductive hypothesis is true, and the goal is exactly the same as the inductive hypothesis, we can simply indicate that we have proven the goal. We do this be the <code>assumption</code> tactic, and then close off the proof with the <code>QED</code> tactic Listing <a href="#lst:assumption_tactic">14</a>. This then accepts the proof as true Listing <a href="#lst:assumption_state">15</a>.</p>
<div id="lst:assumption_tactic" class="listing">
<p>Listing 14: Running the assumption tactic</p>
<pre><code>assumption
QED</code></pre>
</div>
<div id="lst:assumption_state" class="listing">
<p>Listing 15: State after running the assumption tactic</p>
<pre><code>Proof accepted</code></pre>
</div>
<p>It should be noted that the tactic we wrote out are akin to deduction rules, however, there is a problem with this approach, and the problem should become clear once we write down all the commands that have been put into the prover.</p>
<div id="lst:final_proof_script" class="listing">
<p>Listing 16: Final Proof script</p>
<pre><code>Prove: f(x) = x * (x - 1) / 2
introduce
induction x
simplify
reflexivity
unfold f
expand (x + 1) * x
subtract both sides x
replace x with (2 * x / 2)
combine fraction
replace ( + x - 2 * x) with ( - x)
factorise (x * x - x)
assumption
QED</code></pre>
</div>
<p>These proof scripts are very difficult to understand statically, that is it’s difficult to formulate the reasoning behind the proof simply by looking at the list of tactics that were used to prove the proposition. Our understanding of the tactic were aided due to our knowledge of the current state, and understanding However, when looking at the script without the context of the state, they are often very difficult to follow. Especially if the scripts are more complicated than this one.</p>
<h2 id="cognitive-dimensions">Cognitive Dimensions</h2>
<p>Usability problems with ITPs have been noted in the past. In particular, it was completed as part of Kadoda’s PhD thesis in 1999 <span class="citation" data-cites="kadoda_formal_1997">[<a href="#ref-kadoda_formal_1997" role="doc-biblioref">49</a>]</span>. In their thesis, Kodada used Cognitive Dimensions of Notation to classify and sort usability issues. With ITPs.</p>
<p>Cognitive Dimensions of Notation is a framework proposed by Green <span class="citation" data-cites="green_usability_1996">[<a href="#ref-green_usability_1996" role="doc-biblioref">37</a>]</span>, as a way of discussing the design trade-offs of visual programming languages, but has been applied elsewhere for a variety of notations. These dimensions are not an evaluation framework for notations, as often increasing one dimension will also change other dimensions, and different tasks may require different dimensions. For instance, in textual ITPs, dependencies are not shown between theorems, and doing so would increase the Diffuseness of the notation, allowing less to be shown and understood on a single screen. However, debugging why some theorem might fail given a change in other theorems would aid from a more diffuse representation showing the hidden dependencies.</p>
<p>Cognitive Dimensions focus mainly on the way that users understand and work with the meaning of the program. Cognitive Dimensions make an important distinction between difficulties of understanding and working with the notation vs. difficulties with the actual problem itself. Because proving theorems is a very cognitively demanding task, and a lot of that difficulty is inherit to the problem of proving theorems, and no amount of notation will solve it. As of such, we need to focus on ways that the notation can be improved to remove as many difficulties as we can that are not inherit.</p>
<p>Cognitive Dimensions of Notations has been adopted as a way of evaluating the usability of ITPs in Kadoda PhD thesis <span class="citation" data-cites="kadoda_desirable_1999">[<a href="#ref-kadoda_desirable_1999" role="doc-biblioref">50</a>]</span>. In their thesis, they simply use the dimensions as a framework for constructing a questionnaire about possible usability issues with ITPs. We derive our definitions of Cognitive Dimension as applied to ITPs from her thesis.</p>
<p>This thesis will be using Cognitive Dimensions of Notations framework to classify different usability problems. The Cognitive Dimensions of Notations and their definitions are presented:</p>
<p><strong>Abstraction Gradient</strong>: Does the ITP offer ways of abstracting components? Abstraction here refers to methods, classes and encapsulation. Green classifies notations as either being abstraction-hating, abstraction-tolerant or abstraction-hungry. An abstraction-hating ITP would be one that forces the user to work with low level constructs often. An abstraction-tolerant ITP would be one that gives some methods for abstraction, but still nevertheless requires constant low level interaction. An abstraction-hungry ITP would offer many methods of abstraction, that could even in the end obscure what is actually happening behind the scenes.</p>
<p><strong>Closeness of Mapping</strong>: Closeness of Mapping is how similar the notation is to the problem domain. At some point, a representation of the problem has to be put into notation suitable for the ITP. The easier this is to do the better the closeness of mapping, or how close the proof state is represented vs what the user would expect.</p>
<p><strong>Consistency</strong>: Once the user know the basics of an ITP, how much of the rest can be inferred? A notation that is not consistent would require constant lookup of features in the theorem prover. Consistency is particularly important for learning ITPs. Consistency can become an issue when there are a large amount of abstractions.</p>
<p><strong>Error-Proneness</strong>: Is it easy to make careless mistakes? A common "careless mistake" in theorem provers is trying to apply a tactic in a textual theorem prover that is not valid for the current proof state.</p>
<p><strong>Diffuseness</strong>: How much does it represent a proof relative to the complexity of the proposition proven? This is an easier Cognitive Dimension to measure, and represents the verbosity of the notation. ITPs with high diffuseness often have lower abstractions and are easier to understand, but more difficult to change.</p>
<p><strong>Hard Mental Operations</strong>: Are there parts of the notation that require getting out a pencil and paper to understand what it means? The domain of ITPs by it’s very nature requires Hard Mental Operations, so it’s important to separate the inherit difficulty vs difficulty created by the notation. Hard Mental Operations may arise out of particularly complicated tactics, especially since tactics can be composed together. An ITP with a consistent set of tactics would reduce Hard Mental Operations.</p>
<p><strong>Hidden Dependencies</strong>: Are there dependencies in the notation that are not presented? In ITPs and programming languages, it’s usually possible to find what a function/lemma references, but is difficult to find what lemmas/functions reference the one we are working in. Furthermore, automation often uses lemmas in the context without indicating at all that it is using them. This makes the issue of hidden dependencies even more difficult. An ITP with low hidden dependencies makes these dependencies between parts of the program explicit</p>
<p><strong>Perceptual cues</strong>: Does the notation force the user to make decisions before they have the information they need to make it? Especially for novice users, ITPs need to allow the user to explore different paths for proving a statement. This often represents a premature commitment as the user has to commit to a strategy before evaluating whether that strategy would work. ITPs that offer undo features and allow postponing making decisions require less premature commitment.</p>
<p><strong>Premature commitment</strong>: Does the notation force the user to make decisions before they have the information they need to make it? Especially for novice users, ITPs need to allow the user to explore different paths for proving a statement. This often represents a premature commitment as the user has to commit to a strategy before evaluating whether that strategy would work. ITPs that offer undo features and allow postponing making decisions require less premature commitment.</p>
<p><strong>Progressive Evaluation</strong>: Does the system give adequate feedback? Error messages, display of current proof state and ability to work with incomplete proofs are all features of progressive evaluation. Getting feedback from the system is absolutely essential for learning the ITPs.</p>
<p><strong>Role Expressiveness</strong>: Is it easy to identify what the purpose of a component is? Lack of role expressiveness, particularly within the proofs of textual ITPs, was one of the main motivations of this study. It is often very difficult on retrospect to identify how the components of a proof relate to each other. An ITP with high Role Expressiveness would make it clear how a lemma or component of a proof contributes to the proof.</p>
<p><strong>Secondary Notation</strong>: Are there avenues for comments, colours and representation of the code that helps with comprehension? A Secondary Notation is a way of representing understanding by not changing the actual meaning of the notation. ITPs that offer comments, colours and whitespace grouping help with representing secondary notation.</p>
<p><strong>Viscosity</strong>: Is it easy to make a change in the system? ITPs with low abstraction make it difficult to make changes. Sometimes a small difference to what the user is wanting to prove requires a disproportionate change of the proof. ITPs with high viscosity make it difficult to change.</p>
<p><strong>Visibility and Juxtaposability</strong>: How easy is to get a particular piece of desired information? How easy is it to compare part of the proof with proofs elsewhere? Sometimes critical information is difficult to obtain when creating or understanding a proof state. A common example is being able to inspect intermediate proof steps. When a proof relies heavily on automation, it is sometimes difficult to understand how the automated tactic managed to get in a particular proof state. Having this information helps understand the proof and how to move forward. ITPs with low visibility make it difficult to find such information. Juxtaposability is showing two parts of the system side by side. This is important as often a proof might only be a refinement of a previous proof, and might need to be understood in context.</p>
<h2 id="research-questions">Research Questions</h2>
<p>This thesis was inspired by the difficulty in reading static proof scripts. Some provers have already moved to attempt to fix this problem. For instance, Isabelle’s Isar language offers a different way of proving propositions that embeds more state, and helps the user understand the proof. It would be therefore valuable to determine what usability issues have been reported, what has been done to fix them, and whether solutions from some ITPs could be used to help other provers.</p>
<p>And finally, the secondary motivation of this thesis is to encourage further use and development of ITPs. So it would be valuable to create a decision tool that helps a user determine which ITP, if any, should be used for a particular project.</p>
<p>Hence, the research questions for this thesis are:</p>
<p>RQ1 <em>What usability issues and solutions have been mentioned in literature regarding ITPs?</em></p>
<p>This research question was chosen to better understand the context of the study. This was answered by a systematic literature review in Section <a href="#sec:literature_review">3</a>.</p>
<p>RQ2 <em>To what extent to these usability issues exist at the latest versions of ITPs?</em></p>
<p>This research question was chosen due to the continual development of ITPs. It is answered by a living review in Section <a href="#sec:results">4</a>.</p>
<p>RQ3 <em>What, if any, ITP should be used for a specific project?</em></p>
<p>Finally, this research question was chosen as being important for the aim of encouraging more development in the field of ITPs and the creation of more verified software. It is answered by a living review in Section <a href="#sec:results">4</a>.</p>
<h1 id="methodology">Methodology</h1>
<p>In this section, we go over the methodology for answering our research questions. We will structure our systematic literature review, and outline our contribution of a separate living review.</p>
<p>The natural method for answering RQ1 is to perform a systematic literature review. This literature review intends to identify and categorize usability issues related to different theorem provers. We outline the methodology for this review in Section <a href="#sec:review_methodology">2.1</a>.</p>
<p>Answering RQ2 requires going through the theorem provers and identifying the issues. However, ITPs are continually in development, and any issue that arises could be solved at a future date. As of such, we created a <strong>living review</strong> to answer this question.</p>
<p>A living review is a literature review of a field that updates periodically to reflect the current state of the research. These reviews are often published electronically, such as to a website. The goal of a living review is to ensure that the review never goes stale, and can be used as a reference years to come.</p>
<p>Our review looks through more than just literature, and attempts to directly track progress towards fixing usability problems in ITPs. The methodology for the living review is detailed in Section <a href="#sec:living_review_meth">2.2</a>. This living review will gather information about ITPs directly semi-automatically in order to keep up to date. This living review is the main contribution in this thesis.</p>
<p>It differentiates itself from a normal review by updating automatically over time, being an interactive software product, and existing as a decision tool for users.</p>
<p>The creation of this living review will answer RQ3 and RQ2, and provide descriptions of the current state of the field for ITPs.</p>
<h2 id="sec:review_methodology">Systematic Literature Review Methodology</h2>
<p>In this section is to outline the methodology for our systematic literature review. The goal is to answer RQ1, and identify usability issues in literature.</p>
<p>To start, A preliminary ad-hoc literature review will be done in order to survey what usability problems exist in ITPs. This preliminary review came from a search for “usability interactive theorem provers" on the ACM digital library and Google Scholar. The review found several papers on the topic. This will be done to better understand the keywords that people use when discussing usability problems. We then attempted to construct a query that would match these papers and also other papers in the field.</p>
<p>The query constructed from this process was as follows:</p>
<pre><code>    (&quot;Interactive&quot; OR &quot;Deductive&quot;) 
AND (&quot;prover&quot; OR &quot;provers&quot; OR &quot;proving&quot; OR &quot;verifier&quot;) 
AND (&quot;usability&quot; OR &quot;user&quot; OR &quot;users&quot;)`</code></pre>
<p>This query has a large amount of quotes and exact text. The reason for this is that both in many databases, looking up “prover” will return you papers that include the much more common and less relevant term “prove.” Further, not quoting “usability” has the unfortunate consequence of returning papers that contain the word “use.” As of such, we have a very specific query.</p>
<p>We searched the following databases using this query string:</p>
<ul>
<li>Scopus</li>
<li>DBLP</li>
<li>Springer Link</li>
<li>Science Direct</li>
<li>ACM</li>
<li>IEEE</li>
<li>Xplore</li>
</ul>
<p>From the papers discovered in this way, we went through the abstracts and discerned whether the paper was relevant to the research question.</p>
<p>Our inclusion criteria for the papers inclusion and exclusion criteria in the systematic literature review were the following:</p>
<ul>
<li>A peer review published paper AND</li>
<li>Notes particular usability issues with theorem provers OR</li>
<li>Offers direct recommendations to the improvement of the usability of interactive theorem provers</li>
</ul>
<p>From the papers that were deemed relevant to the research question, we found papers that cited the papers discovered. That is, we applied forward snowballing <span class="citation" data-cites="Snowballing">[<a href="#ref-Snowballing" role="doc-biblioref">86</a>]</span>.</p>
<p>We then tried to discover whether these papers were relevant to the research question, and repeated the process of forward snowballing until there were no more papers discovered.</p>
<p>We then analysed the identified papers to discover:</p>
<ul>
<li>The problems and/or solution to usability of interactive theorem provers</li>
<li>Which theorem prover the issue is relevant to</li>
<li>Evidence behind issues and proposed solutions</li>
</ul>
<p>The issues were then categorized by Green’s Cognitive Dimensions of Notations <span class="citation" data-cites="green_usability_1996">[<a href="#ref-green_usability_1996" role="doc-biblioref">37</a>]</span>. This literature review therefore will answer RQ1.</p>
<h2 id="sec:living_review_meth">Living Review Methodology</h2>
<p>The living review has the end goal of determining whether usability issues still exist, and then further offering a tool to help decision about ITPs (RQ3) but also answer whether usability issues still exist in the newest versions of ITPs (RQ2).</p>
<p>The choice of what topics should be covered in the living review were informed by the systematic literature review. All of these options for the scope of the living review will be justified later. We chose to focus on three things:</p>
<p>Mathematical Scope. Does the library implement enough mathematical fundamentals? Often it becomes difficult to work with theorem provers with small libraries, as you may always have to go back to prove trivial things. Math scope is therefore an important usability issue. This living review collects math modules from the theorem provers and then classifies them. This allows for a good comparison between the scope of different ITPs. This is the primary contribution of this thesis.</p>
<p>We further included a discussion of counterexample generators and math notation as a minor contribution on top of this. Counterexample generators are software that attempts to disprove the proposition you are trying to prove by providing a counterexample. It does this so that you can identify if there are any problems with your specification. Counterexample generators therefore help the user better understand the proposition they wish to prove. This living review discusses the support for counterexample generators among ITPs.</p>
<p>Finally, because proving software correct often requires the use of mathematics, often being allowed to use mathematical notation can be useful to make it easier to read and understand the items they are being asked to prove. The review includes a discussion on support for mathematical notation.</p>
<p>The following sections describes the methodology in detail. First, we discuss the choice of Interactive Theorem Provers included within the review in Section <a href="#sec:chosing_itps">2.2.1</a>. Then, we discuss the methodology used in evaluating the scope of the library in Section <a href="#sec:scope_of_library_meth">2.2.2</a>. Then, we discuss the methodology for evaluating support for counterexample generators in Section <a href="#sec:counterexample_meth">2.2.3</a>. Finally, we discuss the methodology for evaluating support for math notation in Section <a href="#sec:math_notation_meth">2.2.4</a>.</p>
<h3 id="sec:chosing_itps">Choosing Interactive Theorem Provers to Cover</h3>
<p>In this section, we discuss the choice of which ITPs to cover as part of the living review.</p>
<p>A reasonable approach to this would be to reference a past review and borrow their scope of ITPs. This was the approach that we took. The newest review in the field is currently <span class="citation" data-cites="nawaz_survey_2019">[<a href="#ref-nawaz_survey_2019" role="doc-biblioref">63</a>]</span>. The ITPs in this review include Isabelle, Coq, HOL, Agda, PVS, LEO-II, Watson, Yarrow, Atelier B, Metamath, Twelf, Mizar, RedPRL, JAPE, LEO-II, Getfol, and Z/EVES.</p>
<p>However, we noted a couple of issues with this consideration of ITPs. In particular, it seemed to favour reviews of older ITPs, and didn’t include successful ITPs that have come out more recently.</p>
<p>One clearly missing consideration was that of Lean <span class="citation" data-cites="Lean">[<a href="#ref-Lean" role="doc-biblioref">61</a>]</span>, a highly popular ITP that’s more often used by mathematicians. Lean is mentioned within the review as a ‘newer ITP’ but is not considered as part of the review. We chose to add Lean, particularly because of its large community based mathematical library. It would be difficult to make a comparison between mathematical libraries, as we intend to do, without including this one.</p>
<p>Secondly, there were some provers that were included within this review that are currently abandoned. Those two provers were Yarrow, and Watson. These two provers had their last releases in 1999 and 2001 respectively. Considering the rate of development of ITPs, these were removed due to meeting a very conservative definition of being abandoned.</p>
<p>Finally, the last modification that was made was that the survey referenced “HOL” as a theorem prover. HOL is not a single ITP but has several implementations, including HOL4 <span class="citation" data-cites="HOL4">[<a href="#ref-HOL4" role="doc-biblioref">78</a>]</span>, HOL Light <span class="citation" data-cites="HOL_Light">[<a href="#ref-HOL_Light" role="doc-biblioref">41</a>]</span>, ProofPower <span class="citation" data-cites="ProofPower">[<a href="#ref-ProofPower" role="doc-biblioref">70</a>]</span> and HOL Zero <span class="citation" data-cites="HOL_Zero">[<a href="#ref-HOL_Zero" role="doc-biblioref">2</a>]</span>. For the sake of their review, keeping these separate was appropriate as only properties of different theorem provers were discussed, and these properties remained largely the same for each implementation. However, because this living review covers mathematical libraries, which will change depending on the implementation, it will require comparing between implementations. As of such, “HOL” was split into its two most popular interventions, HOL4 and HOL Light. These two were chosen as they have larger mathematical libraries, whereas HOL Zero and ProofPower do not. Including HOL Zero or ProofPower would therefore not add much value to the living review.</p>
<p>This left the following ITPS in scope for the review: ACL2 <span class="citation" data-cites="ACL2">[<a href="#ref-ACL2" role="doc-biblioref">51</a>]</span>, Agda <span class="citation" data-cites="Agda">[<a href="#ref-Agda" role="doc-biblioref">64</a>]</span>, Atelier B <span class="citation" data-cites="Atelier_B">[<a href="#ref-Atelier_B" role="doc-biblioref">25</a>]</span>, Coq <span class="citation" data-cites="Coq">[<a href="#ref-Coq" role="doc-biblioref">19</a>]</span>, Getfol <span class="citation" data-cites="Getfol">[<a href="#ref-Getfol" role="doc-biblioref">33</a>]</span>, HOL Light <span class="citation" data-cites="HOL_Light">[<a href="#ref-HOL_Light" role="doc-biblioref">41</a>]</span>, HOL4 <span class="citation" data-cites="HOL4">[<a href="#ref-HOL4" role="doc-biblioref">78</a>]</span>, Isabelle <span class="citation" data-cites="Isabelle">[<a href="#ref-Isabelle" role="doc-biblioref">68</a>]</span>, JAPE <span class="citation" data-cites="JAPE">[<a href="#ref-JAPE" role="doc-biblioref">21</a>]</span>, LEO-II <span class="citation" data-cites="LEO-II">[<a href="#ref-LEO-II" role="doc-biblioref">17</a>]</span>, Lean <span class="citation" data-cites="Lean">[<a href="#ref-Lean" role="doc-biblioref">61</a>]</span>, Metamath <span class="citation" data-cites="Metamath">[<a href="#ref-Metamath" role="doc-biblioref">65</a>]</span>, Mizar <span class="citation" data-cites="Mizar">[<a href="#ref-Mizar" role="doc-biblioref">34</a>]</span>, PVS <span class="citation" data-cites="PVS">[<a href="#ref-PVS" role="doc-biblioref">73</a>]</span>, RedPRL <span class="citation" data-cites="RedPRL">[<a href="#ref-RedPRL" role="doc-biblioref">5</a>]</span>, Twelf <span class="citation" data-cites="Twelf">[<a href="#ref-Twelf" role="doc-biblioref">69</a>]</span>, and Z/EVES <span class="citation" data-cites="Z/EVES">[<a href="#ref-Z/EVES" role="doc-biblioref">74</a>]</span>.</p>
<h3 id="sec:scope_of_library_meth">Scope of Library</h3>
<p>This section reviews the methodology for investigating the scope of libraries within the living review. We have the goal of determining whether mathematical foundations were covered for any given subject area, and by which provers they are covered by.</p>
<p>On a high level, the mathematical libraries for different ITPs will be decomposed into modules, and each of these modules are classified according to which section of mathematics they cover. This way we can identify which ITPs cover which mathematical topics, and make meaningful comparisons between them.</p>
<figure>
<img src="Images/summary.png" id="fig:classification_summary" alt="Figure 2: Flow chart for classifying mathematical libraries" /><figcaption aria-hidden="true">Figure 2: Flow chart for classifying mathematical libraries</figcaption>
</figure>
<p>The flowchart shown in Figure <a href="#fig:classification_summary">2</a> has an overview of the methodology to be used used to evaluate the scope of the mathematical libraries.</p>
<h4 id="sec:identifying_math_lib_meth">Step 1: Identifying Mathematical Libraries</h4>
<p>We start by identifying mathematical libraries. For the sake of this analysis, we also include community contributions, such as package management systems, as part of the scope. As of such, a “library” will refer to both a library that comes along with an ITP (often titled a “standard library”) as well as a collection of community contributions, such as package management system.</p>
<p>For each ITP, it will be determined whether they first had a body of code similar to a library. If it did, then it was determined whether the library simply meets the following inclusion criteria:</p>
<p><strong>IC1:</strong> The library contains mathematical theorems. Libraries that do not prove theorems are often libraries that are about simple constructions of data types.</p>
<p><strong>IC2:</strong> The library contains more than 15000 lines of proof code worth of math theorems. This, as identified later, corresponds to about 10 modules. If the library doesn’t offer that many modules, then we consider this to not be of interest to a mathematician.</p>
<p>For each ITP, we look for two different things. Firstly, whether the ITP has a mathematical library, and secondly, if the ITP has something resembling a package management system. If the ITP had either or both of these things, then they were decomposed into mathematical modules, as per the next section.</p>
<h4 id="sec:collecting_modules_meth">Step 2: Collecting Modules</h4>
<p>The next step is to determine what constituted a module for each of the libraries. We define a <strong>module</strong> as a single unit of work contributed to an ITP. This is used to reason about contributions and the scope of the ITP. We define this concept as in our analysis we compare components of standard libraries with packages in package management systems, so we refer to a contribution under the same name.</p>
<p>A collection of resources can be of three types: “package,” “small” or “large.” These are chosen to give a fair comparison between modules.</p>
<p>If the module came from a community contribution, such as Isabelle’s Archive of Formal Proofs or Coq’s package management system, then it is considered a “package” type. Meaning a module is considered to be whatever a unit of contribution is. For instance, a package is considered a module in Coq’s package management system, or a submission in the Archive of Formal Proofs. We consider this to be a natural mapping because there are very little other options in defining a module in a package management system. It would both be unusual to split up packages into their smaller components due to having non standardised structure and also unusual to define a module as a collection of packages. It also means that the module is understandable, linkable and explorable in the review.</p>
<p>If the modules came from a “standard library,” we attempted to divide the standard library into “package sized” sections, in order to make a fair comparison between contributions. Because a package, as above, is a natural mapping to modules, and standard libraries are often much larger than a single package, we need to split the library up in a way that makes each component to a package. To do this, we exploited that most libraries are structured in a hierarchy, so we split the library as determined by how far down the hierarchy we need to go until we get “package sized” sections. If only one level of the hierarchy is needed, it is classified as “small,” if two levels are needed, it is classified as “large.”</p>
<p>To determine whether a library is small or large, we first have a target module size, which we define to be 1500 lines of proof code. Then, the mean module size is calculated, and it is determined whether a small or large library is closer to 1500 lines on a log scale. Whatever is closer we assign that size to the library.</p>
<p>These modules are then collected from the internet automatically from the webpage using a python script. The script is designed so that it can update the review to newest modules automatically, ensuring that the users are always viewing the most up to date version of these libraries.</p>
<p>This script will be run monthly to ensure that the review is up to date.</p>
<p>From the modules, a number of elements were collected. The name of the module, a description if it was available, authors if it was available, and a URL to the module. These will all be presented to the user when discovering different modules supported by different ITPs.</p>
<h4 id="sec:classifying_modules_meth">Step 3: Classifying modules</h4>
<p>Our next step is to classify or exclude each module that we have collected.</p>
<p>There are a number of exclusion criteria for this classification. These exclusion criteria exist for modules that would be difficult or impossible to classify as a part of a mathematical topic. Those possible exclusion criteria include:</p>
<p><strong>EC1:</strong> Utility, The module only offers a utility that is only relevant to this ITP. For instance, many ITPs double as programming languages, so any modules that allow for programming that works with the system such as file operations are excluded. This also includes modules that are integrations with other tools, or simply initialization libraries that only reference other modules.</p>
<p><strong>EC2:</strong> No Documentation, If the module doesn’t have any documentation or description of purpose, it is excluded from the classification. It should be noted that the definition of documentation is very minimal in this case. The module doesn’t need to have much documentation, one sentence of its purpose is enough. However, if it is missing, the module is difficult to classify and is excluded.</p>
<p><strong>EC3:</strong> Only Documentation: If the module is simply documentation and doesn’t provide any new resources, it is also excluded.</p>
<p><strong>EC4:</strong> Deprecated: If the module has been marked or considered deprecated, then it is also excluded.</p>
<p>Excluded modules will be marked as excluded, and the reason for exclusion placed in the living review.</p>
<p>If a module doesn’t fall under any exclusion criteria, then the modules is ready to be classified. Each module is then assigned a mathematical subject that it is relevant to.</p>
<p>The topics these modules were classified under come from the Mathematical Subject Classification 2020 (MSC2020) <span class="citation" data-cites="msc2021">[<a href="#ref-msc2021" role="doc-biblioref">9</a>]</span>. MSC2020 is a classification of mathematical subjects that is often used for mathematics papers. Each topic is given a code representing its classification, One such example of a code is 68P05, the code for work about data structures. The code is split up into three sections, the top level is represented by a top level mathematical field, For instance, the 68 in 68P05 means that it’s in the field of Computer Science. To refer to the general field of Computer Science, it is referred to is 68-XX, with the -XX meaning that it could be anything under this field. The next level of classification is represented by a letter. In this case, the P in 68P05 refers to subclassification of “Theory of Data” under “Computer Science.” If one wishes to refer to the mid level classification, then one can do so like 68Pxx, by replacing the final two numbers with “x”s. Finally, the last two numbers represents the final level of classification. In this case, the 05 refers to “Data Structures” under “Theory of Data” under “Computer Science.”</p>
<p>Some further examples of MSC Classifications are:</p>
<p><strong>68Nxx</strong>: Theory of Software</p>
<p><strong>68N15</strong>: Theory of Programming Languages</p>
<p><strong>13-XX</strong>: Commutative Algebra</p>
<p><strong>13Axx</strong>: General commutative ring theory</p>
<p><strong>13A50</strong>: Actions of groups on commutative rings; invariant theory</p>
<p>This classification is chosen in order to be familiar to mathematicians, and ensure that modules can be classified with enough specificity.</p>
<p>If the module also comes with some form of category (for instance, Coq’s package management system allows adding categories to a package, indicating the subject it covers, or large library modules use the top level module as a category), then the classification of the package is “guessed.” This is done by mapping the category to a classification. The module can be browsed and seen in the tree, but however is marked as “unverified.” If the module doesn’t come with a category, then the module is marked as “unclassified.”</p>
<p>Then, a module’s description (for instance, abstracts, package descriptions, names) is inspected manually and a classification is given to it. The package is then considered to be “verified.”</p>
<p>Finally, there is a limitation in our study, in that a very large number of mathematical topics have been covered by ITPs. As of such, there are some subjects that would require a very wide and professional understanding of the many facets and areas of mathematics in order to classify correctly. Any package that is therefore outside of the ability of the author to classify, is labeled as “needs professional” during verification. However, these modules are at the very least categorized vaguely into a top level MSC classification. For example, the author doesn’t have a strong understanding of partial differential equations, so any package that is from the field of partial differential equations is marked as so, but not classified with any specificity beyond that.</p>
<p>This means that modules can be placed into five different states:</p>
<p><strong>Unclassified</strong>: The module is included in the system, but the system does not have any idea of what math classification it falls under, nor has it been verified.</p>
<p><strong>Unverified</strong>: The module’s classification has been guessed automatically based on a category provided by the resource providing the module. For instance, Isabelle’s Archive of Formal Proofs categorizes modules by topic in their index, and the classification of the module is guessed based on this.</p>
<p><strong>Excluded</strong>: The module has been inspected and meets one of the exclusion criteria. This excluded module is not classified and removed from the study.</p>
<p><strong>Needs Professional</strong>: The module has been verified but classified to a top level. It requires a professional mathematician to classify more specifically.</p>
<p><strong>Verified</strong>: The module has been verified manually to be in the correct classification. This is the final desired state of a module.</p>
<p>States that are <strong>Unclassified</strong> or <strong>Unverified</strong> represents states that are incomplete. As in, at some later point, manual intervention is required to “complete” the classification. The reason why we discuss and include unclassified and unverified modules in the analysis is that we would prefer to present all the resources available with a prover to a viewer, even the newest resources, before a human goes into the system to verify a package. The goal however, is to have no or little packages in the unclassified and unverified state.</p>
<p>A static snapshot of the work presented in Section <a href="#sec:results">4</a> contain no Unclassified on Unverified newer, but the living version of it may, as it continues to collect newer module.</p>
<h3 id="sec:counterexample_meth">Counterexample Generator Methodology</h3>
<p>When proving a theorem, a counterexample generator attempts to find an example for which the theorem does not hold. This helps the user better understand when the theorem and the statement that they wish to prove.</p>
<p>A literature review was performed in order to identify counter example generators, and the ITPs systems that they have support.</p>
<p>This is a very minor contribution, but simply attempts to give a very brief overview of support for counterexample generators for theorem proving.</p>
<h3 id="sec:math_notation_meth">Math Notation Methodology</h3>
<p>Finally, as another minor contribution, we include details about which theorem provers use mathematical notation in proving theorems.</p>
<p>Determining whether an ITP uses mathematical notation in proofs can easily be done by examining example ITP code, and determining whether they use math notation. Which ITPs support mathematical notation was further included as a minor contribution to the living review.</p>
<h3 id="general-features-of-about-itps">General features of about ITPs</h3>
<p>To compare between different ITPs, we must first start by collecting general features about them. This is tied in RQ3, as working out whether an ITP should be used on a project will require having some general information about it.</p>
<p>We decided to use a 2019 Systematic Literature Reviews on Theorem Provers as our starting dataset <span class="citation" data-cites="nawaz_survey_2019">[<a href="#ref-nawaz_survey_2019" role="doc-biblioref">63</a>]</span>. This review went through 27 theorem provers and described the features that each prover had. This was converted into a dataset and used to compare general features.</p>
<p>This dataset contained several properties about ITPs, and properties to compare between them.</p>
<p>The full set of properties we used from the dataset are:</p>
<ul>
<li>What the ITP is based on (Syllogism, Type Theory, Etc)</li>
<li>The logic of the ITP</li>
<li>The Truth value of the ITP</li>
<li>Whether it supports Set theory</li>
<li>Whether it has a library</li>
<li>What the ITPs calculus is</li>
<li>Whether the architecture is modular or monolithic</li>
<li>The programming language it’s implemented in</li>
<li>Whether it has a GUI or CLI interfaces</li>
<li>The Platforms its supported on (Windows, Mac, Linux)</li>
<li>Whether it has an IDE</li>
<li>When it was first released.</li>
<li>Its latest release</li>
</ul>
<p>A lot of these features (such as the logic, truth value etc) require explanations as to what they refer to. These explanations will be included within the tool. This allows people unfamiliar to the field to learn what the components of ITPs are and why they are important.</p>
<p>Some newer ITPs were not included in the dataset, such as Lean, F* and Idris. These were added manually to the dataset.</p>
<p>The systematic literature review we source our data from however, is already out of date for the latest release of its provers. As of such, we have a python script that automatically retrieves whether any newer versions of a prover have been released by checking GitHub Tags. It gets the latest tag to be published and adds that as the latest release on the living review, ensuring that the review doesn’t go out of date by having newer releases.</p>
<h1 id="sec:literature_review">Literature Review</h1>
<p>The amount of papers found in each section of the review are shown in Table <a href="#tbl:litresults">1</a>. This totals to 36 papers found on the topic.</p>
<p>There was a surprisingly small amount of papers caught by query in comparison to snowballing. This is because many papers that discuss usability issues about ITPs do not tackle the problem directly (28/38 of the papers), but rather showcase a feature that has been coded into an ITP interface. These features do indeed solve a usability problem implicitly, and represent the bulk of the work on improving interfaces for ITPs. However, comparatively little research has been done identifying the issues with ITP interfaces and empirically comparing these user interface modifications for merit (10/38 of the papers).</p>
<div id="tbl:litresults">
<table>
<caption>Table 1: Literature review papers</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Round</th>
<th style="text-align: left;">Found</th>
<th style="text-align: left;">Relevant</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Query</td>
<td style="text-align: left;">45</td>
<td style="text-align: left;">14</td>
</tr>
<tr class="even">
<td style="text-align: left;">Snowball 1</td>
<td style="text-align: left;">121</td>
<td style="text-align: left;">14</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Snowball 2</td>
<td style="text-align: left;">191</td>
<td style="text-align: left;">5</td>
</tr>
<tr class="even">
<td style="text-align: left;">Snowball 3</td>
<td style="text-align: left;">99</td>
<td style="text-align: left;">2</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Snowball 4</td>
<td style="text-align: left;">44</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Snowball 5</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: left;">504</td>
<td style="text-align: left;">36</td>
</tr>
</tbody>
</table>
</div>
<p>When going through papers, it was interesting to find a large amount of papers proposing user interface models, but not actually identifying the problems that they solve, nor evaluating their effectiveness. In fact, out of the 28 papers that showcased user interface improvements, only 2 papers evaluated the their interface improvement to without the improvement <span class="citation" data-cites="hentschel_empirical_2016 berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>, <a href="#ref-hentschel_empirical_2016" role="doc-biblioref">44</a>]</span>. That there is not enough empirical studies verifying usability issues has been cited as an issue that needs to addressed in the past <span class="citation" data-cites="hahnle_deductive_2019">[<a href="#ref-hahnle_deductive_2019" role="doc-biblioref">39</a>]</span>.</p>
<p>The following sections outline usability issues and solutions to those issues. Tables are included outlining the usability issues mentioned. If the same problem is mentioned in two papers, it is given two rows.</p>
<p>The theorem prover column refers to the theorem prover the usability issue was found in. If the problem is a general comment “General" is written.”Textual" means a theorem prover that uses proof script to solve theorems, such as Isabelle/HOL, Coq, Agda. “Direct Manipulation" means a theorem prover that uses direct manipulation to solve theorems, such as KeY.</p>
<p>The discovered column indicates the evidence that that problem exists. "Suggested" simply means that problem or solution was simply inferred or has not actually been evaluated as effective. Other values indicate the type of study that the paper used to observe or evaluate this problem or solution.</p>
<h2 id="theorem-provers">Theorem Provers</h2>
<p>First of all, a brief overview of the theorem provers is in order.</p>
<h4 id="key">KeY</h4>
<p>KeY is a Direct Manipulation theorem prover, meaning that unlike Textual theorem provers, does not prove theorems by writing proof scripts, but instead works by modifying a proof object directly until all proof obligations have been solved. KeY works by annotating Java programs with preconditions and postconditions. These conditions are then fed into KeY as proof obligations. KeY can act as a fully automatic prover, but also allows the user to attempt to find a proof if the prover fails. KeY has also formed the basis of KeYmaera and KeYmaera X, which are for proving properties of hybrid systems.</p>
<h4 id="hol">HOL</h4>
<p>HOL is actually a family of theorem provers. Notably HOL4, ProofPower, HOL Light and HOL Zero. HOL is one of the oldest provers in this list, and HOL Light is known to be used as a lightweight prover, with a very easily checkable kernel. HOL provers are textual, and have a simple type system and use tactics to prove propositions.</p>
<h4 id="isabelle">Isabelle</h4>
<p>Isabelle (also known as Isabelle/HOL, but for this paper will remain as Isabelle to prevent confusion) is one of the most popular theorem provers. The prover has been used for the verification of the SeL4 prover, and exists as the state-of-the-art of ITPs. Isabelle like HOL has a simple type system and is based of the Logic for Computable Functions.</p>
<h4 id="coq">Coq</h4>
<p>Coq is another popular ITP that also supports a dependent type system. It’s based on the Calculus of (Co)Inductive Constructions, which was designed specifically for Coq. Coq has been used to prove the four colour theorem, and create the CompCert certified C compiler.</p>
<h4 id="matita">Matita</h4>
<p>Matita is a theorem prover based on Coq’s Calculus of (Co)Inductive Constructions, and was designed to address many of the pain points in working with Coq. Matita is a much simpler prover that aims to present the theorem prover as editing a mathematical library. As of such, Matita’s solutions to problems are often pain points in Coq (mathematical notation, Tinycals etc).</p>
<p>There are a few other provers also in this review, such as iCon, CardiZ and Dafny. These ITPs are often either coded as proofs of concepts (such as iCon), or are no longer maintained (in the case of CardiZ or Dafny). The problems raised by them however, are often relevant for current day ITPs.</p>
<p>This is by no means a complete list of modern ITPs. Such compilations have been done <span class="citation" data-cites="nawaz_survey_2019">[<a href="#ref-nawaz_survey_2019" role="doc-biblioref">63</a>]</span>. These are only the ITPs discussed in the papers found in the review. There are notable ITPs that are missing from this list that caught us by surprise, including Agda, Lean and Mizar.</p>
<h2 id="abstraction-gradient">Abstraction Gradient</h2>
<p>The problems classified under abstraction gradient are shown in Table <a href="#tbl:abstraction_gradient">2</a>.</p>
<div id="tbl:abstraction_gradient">
<table>
<caption>Table 2: Abstraction Gradient Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Interaction with low level logic</td>
<td style="text-align: left;">Focus Groups</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Missing Library</td>
<td style="text-align: left;">Focus Groups</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>The abstraction gradient Dimension concerns itself with the highest and lowest levels of abstraction that are presented. Are they at the appropriate level of abstraction?</p>
<p>Issues in this dimension were uncommon. KeY was found to require interacting on low level logic formulas consistently. Similar issues with tedious interactions with KeY are mentioned in the viscosity’s section. No solutions were found or suggested to this problem, and it has not been empirically tested.</p>
<p>Focus Groups <span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span> found that Isabelle’s library lacks the appropriate mathematical foundations. Interestingly, this is the only issue of this class and is not mentioned elsewhere, often library issues are more about managing and searching large libraries, which Matita attempts to handle, and correct documentation of libraries. This has not been tested empirically. Other than the implicit solution of providing better library support for theorem provers, no solution has been provided for this problem.</p>
<h2 id="closeness-of-mapping">Closeness of Mapping</h2>
<p>The problems classified under Closeness of Mapping are shown in Table <a href="#tbl:closeness_of_mapping">3</a>.</p>
<div id="tbl:closeness_of_mapping">
<table>
<caption>Table 3: Closeness of Mapping Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Unintuitive mapping between formula and program</td>
<td style="text-align: left;">Focus Groups</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">CardiZ</td>
<td style="text-align: left;">Cannot sketch out proofs</td>
<td style="text-align: left;">Questionnaire</td>
<td style="text-align: left;"><span class="citation" data-cites="kadoda_cognitive_2000">[<a href="#ref-kadoda_cognitive_2000" role="doc-biblioref">48</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Cannot use mathematical notation</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Cannot use mathematical notation</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="asperti_user_2007 zacchiroli_user_2007">[<a href="#ref-asperti_user_2007" role="doc-biblioref">7</a>, <a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>The dimension of Closeness of Mapping is whether the interface maps well to the problem world. For interactive theorem provers, it has to do with how well the proof state is understood in comparison to the actual problem.</p>
<p>Focus groups <span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span> found that because KeY attempts to prove properties through annotations and java source code, it can sometimes be difficult to see how this proof state maps to the program <span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span>. This issue is not mentioned in any other source and not tested empirically. No solutions have been suggested for this.</p>
<p>CardiZ, an ITP that can be used to prove properties of Z specifications, found that the user could not sketch out proofs before an attempt <span class="citation" data-cites="kadoda_cognitive_2000">[<a href="#ref-kadoda_cognitive_2000" role="doc-biblioref">48</a>]</span>. This is the only paper on CardiZ, as CardiZ is not a popular prover. No solutions have been suggested for this.</p>
<p>A common issue that came up with Coq was the inability to use mathematical notation <span class="citation" data-cites="berman_development_2014 asperti_user_2007 zacchiroli_user_2007">[<a href="#ref-asperti_user_2007" role="doc-biblioref">7</a>, <a href="#ref-berman_development_2014" role="doc-biblioref">18</a>, <a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span>. Notation issues are problematic in ITPs. One one hand, theorem provers such as Isabelle and Agda allow using mathematical notation in their theorems. This helps the user understand the theorem in a terse syntax. On the other hand, mathematical notation can often be ambiguous and difficult to type. Isabelle allows using LaTeX style commands such as <code>rightarrow</code> to render math notation, whereas Agda allows Unicode in source files. In order to avoid ambiguity, Coq has no support for math notation, and in response to this, Matita has LaTeX style mathematical notation <span class="citation" data-cites="asperti_user_2007 zacchiroli_user_2007">[<a href="#ref-asperti_user_2007" role="doc-biblioref">7</a>, <a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span>. This issue came up in three different sources.</p>
<h2 id="consistency">Consistency</h2>
<p>The problems classified under Consistency are shown in Table <a href="#tbl:consistency">4</a>.</p>
<div id="tbl:consistency">
<table>
<caption>Table 4: Consistency Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Difficult to know what tactics and lemmas to use</td>
<td style="text-align: left;">Focus Groups</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015 beckert_interaction_2017">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>, <a href="#ref-beckert_interaction_2017" role="doc-biblioref">16</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">HOL</td>
<td style="text-align: left;">Difficult to know what tactic to apply next</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="aitken_interactive_1998">[<a href="#ref-aitken_interactive_1998" role="doc-biblioref">3</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Hard to remember prover specific details</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="nagashima_pamper_2018">[<a href="#ref-nagashima_pamper_2018" role="doc-biblioref">62</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Difficult to know what tactic to apply next</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="mitsch_keymaera_2017">[<a href="#ref-mitsch_keymaera_2017" role="doc-biblioref">59</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle,HOL</td>
<td style="text-align: left;">Difficult to remember names of theorems</td>
<td style="text-align: left;">Observational</td>
<td style="text-align: left;"><span class="citation" data-cites="aitken_analysis_2000">[<a href="#ref-aitken_analysis_2000" role="doc-biblioref">4</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Difficult to find relevant lemmas</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Difficult to find arguments for tactics</td>
<td style="text-align: left;">Observational</td>
<td style="text-align: left;"><span class="citation" data-cites="ringer_replica_2020">[<a href="#ref-ringer_replica_2020" role="doc-biblioref">71</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Bad Library, inconsistent naming</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>Consistency is the Cognitive Dimension of whether, once learning part of the notation, the user is able to infer the rest of the notation.</p>
<p>In textual theorem provers, it is often difficult to remember the name of the next tactic, theorems or lemmas should be applied in any situation. This has been bought up in focus groups <span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span>, observational studies <span class="citation" data-cites="aitken_analysis_2000">[<a href="#ref-aitken_analysis_2000" role="doc-biblioref">4</a>]</span>, surveys <span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span> and suggested as a problem from various other sources.</p>
<p>Solutions to this problem often include choosing applicable tactics by menu <span class="citation" data-cites="aitken_analysis_2000 aitken_interactive_1998">[<a href="#ref-aitken_interactive_1998" role="doc-biblioref">3</a>, <a href="#ref-aitken_analysis_2000" role="doc-biblioref">4</a>]</span> Which has been implemented in Coq through Proof Previews <span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span> and in KeYmaera X <span class="citation" data-cites="mitsch_keymaera_2017">[<a href="#ref-mitsch_keymaera_2017" role="doc-biblioref">59</a>]</span>. Machine learning for choosing appropriate recommendations has been suggested for this problem <span class="citation" data-cites="ringer_replica_2020">[<a href="#ref-ringer_replica_2020" role="doc-biblioref">71</a>]</span>, and has also been implemented through the PaMpeR tool in Isabelle <span class="citation" data-cites="nagashima_pamper_2018">[<a href="#ref-nagashima_pamper_2018" role="doc-biblioref">62</a>]</span>. A second way of tackling this problem is to improve library searching, which was suggested <span class="citation" data-cites="aitken_analysis_2000">[<a href="#ref-aitken_analysis_2000" role="doc-biblioref">4</a>]</span> and is a focus in Matita <span class="citation" data-cites="tassi_interactive_2008">[<a href="#ref-tassi_interactive_2008" role="doc-biblioref">80</a>]</span>. Improving these tools is a promising area for improving the usability of ITPs</p>
<h2 id="diffuseness-terseness">Diffuseness / Terseness</h2>
<p>The problems classified under Diffuseness/Terseness are shown in Table <a href="#tbl:diffuseness">5</a>.</p>
<div id="tbl:diffuseness">
<table>
<caption>Table 5: Diffuseness / Terseness Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Bloated Formulas</td>
<td style="text-align: left;">Focus Groups</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Large proofs correspond to large effort</td>
<td style="text-align: left;">Observational</td>
<td style="text-align: left;"><span class="citation" data-cites="bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>Diffuseness is the Cognitive Dimension of the tersity/verbosity of the syntax. Bloated formulas were mentioned in Isabelle in Focus Groups, and projects with more lines of code were strongly correlated with more effort. No solutions have been suggested to reducing the size of code bases or formulas.</p>
<h2 id="error-proneness">Error Proneness</h2>
<p>The problems classified under Error Proneness are shown in Table <a href="#tbl:error_proneness">6</a>.</p>
<div id="tbl:error_proneness">
<table>
<caption>Table 6: Error Proneness Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Isabelle,HOL</td>
<td style="text-align: left;">Easy to get errors in Object Level Constructions</td>
<td style="text-align: left;">Observational</td>
<td style="text-align: left;"><span class="citation" data-cites="aitken_analysis_2000">[<a href="#ref-aitken_analysis_2000" role="doc-biblioref">4</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle,HOL</td>
<td style="text-align: left;">Incorrect predictions made about tactics</td>
<td style="text-align: left;">Observational</td>
<td style="text-align: left;"><span class="citation" data-cites="aitken_analysis_2000">[<a href="#ref-aitken_analysis_2000" role="doc-biblioref">4</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Difficult to manage namespace</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>Error proneness is the Cognitive Dimension of whether a system allows its users to make errors.</p>
<p>Observational studies have found that in Isabelle and HOL it is easy to make errors in syntax. Considering the frequency of syntax errors, this issue came up surprisingly little other sources. This could be because syntax errors are relatively easy to fix and also decrease with usage. It’s been suggested that this problem could be solved my improving feedback in Object Level syntax input <span class="citation" data-cites="aitken_analysis_2000">[<a href="#ref-aitken_analysis_2000" role="doc-biblioref">4</a>]</span>. A more interesting solution has been implemented for Coq is a structure editor based off keyboard cards <span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span>. This uses rolling chords (like <em>vi</em>) keyboard interfaces to interact with the theorem prover. This means that it is only possible to enter syntactically valid statements. This current solution only works on a subset of Coq’s syntax. It was found to be slightly quicker than using dropdown menus.</p>
<p>Sometimes when applying a tactic, an unexpected result would occur, causing the user to back up and try to understand the current state. This issue could be solved by Proof Previews <span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span>, which allow the user to see a proof state when selecting tactics from a menu without actually applying the tactic. That way the user can cheaply explore tactics to continue in the proof.</p>
<p>Finally, for large verification projects such as SeL4, there is an issue with managing the namespaces of large amounts of theorems and lemmas. No verification of this problem nor solution has been suggested.</p>
<h2 id="hard-mental-operations">Hard Mental Operations</h2>
<p>The problems classified under Hard Mental Operations are shown in Table <a href="#tbl:hard_mental_operations">7</a>.</p>
<div id="tbl:hard_mental_operations">
<table>
<caption>Table 7: Hard Mental Operations Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Hard to understand proof scripts statically</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="zacchiroli_user_2007">[<a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">General</td>
<td style="text-align: left;">Difficult to understand tacticals</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="grov_tinker_2018 lin_understanding_2016">[<a href="#ref-grov_tinker_2018" role="doc-biblioref">38</a>, <a href="#ref-lin_understanding_2016" role="doc-biblioref">55</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">General</td>
<td style="text-align: left;">Proof scripts can become complicated</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="aspinall_towards_2016">[<a href="#ref-aspinall_towards_2016" role="doc-biblioref">8</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>The Dimension of Hard Mental Operations refer to the difficulty in understanding and using the interface on a syntax level. This type of issue is common with ITPs, as the actual domain is complicated, so this is reflected with difficult syntax.</p>
<p>Proofs are hard enough to understand while viewing the dynamic nature of the proof, investigating proof state bit by bit. They are often near impossible to understand statically <span class="citation" data-cites="zacchiroli_user_2007">[<a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span>. This issue has not been investigated empirically, but solutions often involve changing the syntax around proofs. One notable example of this is Isar for Isabelle <span class="citation" data-cites="wenzel_structured_2006">[<a href="#ref-wenzel_structured_2006" role="doc-biblioref">84</a>]</span>, which attempts to mirror how a pen and paper proof is structured.</p>
<p>It is often difficult to understand tacticals, and the problem is made even worse when it is not possible to view the state of a tactical mid way through interaction. This problem has been suggested in several sources <span class="citation" data-cites="grov_tinker_2018 lin_understanding_2016 zacchiroli_user_2007">[<a href="#ref-grov_tinker_2018" role="doc-biblioref">38</a>, <a href="#ref-lin_understanding_2016" role="doc-biblioref">55</a>, <a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span> but never empirically investigated. Solutions to this include representing tacticals as graphs <span class="citation" data-cites="grov_tinker_2018 lin_understanding_2016">[<a href="#ref-grov_tinker_2018" role="doc-biblioref">38</a>, <a href="#ref-lin_understanding_2016" role="doc-biblioref">55</a>]</span>. This solution has not been tested with users.</p>
<p>Proof scripts can also get very complicated for larger propositions. Keeping track of this complexity has been suggested with proof metrics, which are similar to classic code complexity metrics <span class="citation" data-cites="aspinall_towards_2016">[<a href="#ref-aspinall_towards_2016" role="doc-biblioref">8</a>]</span>.</p>
<h2 id="hidden-dependencies">Hidden Dependencies</h2>
<p>The problems classified under Hidden Dependencies are shown in Table <a href="#tbl:hidden_dependencies">8</a>.</p>
<div id="tbl:hidden_dependencies">
<table>
<caption>Table 8: Hidden Dependencies Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Hard to see dependencies between proofs</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="spichkova_human-centred_2017">[<a href="#ref-spichkova_human-centred_2017" role="doc-biblioref">79</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Difficult to patch proofs that have slightly changed</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_evaluating_2012">[<a href="#ref-beckert_evaluating_2012" role="doc-biblioref">13</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Hidden automation dependencies</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Difficult to patch proofs when dependencies change</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Hard to see dependencies between proofs</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="aspinall_towards_2016">[<a href="#ref-aspinall_towards_2016" role="doc-biblioref">8</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>Hidden Dependencies represent dependencies between components that are not shown explicitly. Hidden dependencies are everywhere in theorem provers. Like functions in many programming languages, lemmas can reference the lemmas that they use, but it is difficult to find where a particular lemma has been used. Automation makes this problem even worse, where in Isabelle, an automatic tactic will try lemmas that are above it in the theory. This makes moving lemmas around a theory document difficult. Moving a lemma around a document, even if all the other lemmas it is references are above it, may cause it to fail due to it using a lemma by automation. Monitoring dependencies has been suggested as part of formal proof metrics. It’s been suggested and implemented within CoqPIE to show these dependencies within the IDE <span class="citation" data-cites="roe_coqpie_2016">[<a href="#ref-roe_coqpie_2016" role="doc-biblioref">72</a>]</span>. Tools have also been built to analyse dependencies between Isabelle proofs <span class="citation" data-cites="spichkova_human-centred_2017">[<a href="#ref-spichkova_human-centred_2017" role="doc-biblioref">79</a>]</span>. For automated tactics, Isabelle’s sledgehammer offers a unique solution to showing dependencies. The automatic tactic, after execution, simply prints a set of manual tactics that were used to prove the theorem into the document. That way, all the lemmas that were used in the automated tactic are made explicit <span class="citation" data-cites="bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span>. None of these solutions have been empirically tested for validity.</p>
<p>Furthermore, often changing a definition or proof slightly requires changing the proof in order to match the new definitions. This is a tedious process.</p>
<p>None of these issues have been tested empirically.</p>
<h2 id="perceptual-cues">Perceptual Cues</h2>
<p>The problems classified under Perceptual Cues are shown in Table <a href="#tbl:perceptual_cues">9</a>.</p>
<div id="tbl:perceptual_cues">
<table>
<caption>Table 9: Perceptual Cues Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">HOL</td>
<td style="text-align: left;">Difficult to understand proof state</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="kadoda_cognitive_2000">[<a href="#ref-kadoda_cognitive_2000" role="doc-biblioref">48</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Difficult to understand proof state</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="hentschel_integrating_2016">[<a href="#ref-hentschel_integrating_2016" role="doc-biblioref">43</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">General</td>
<td style="text-align: left;">Difficult to understand proof state</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="eastaughffe_support_1998">[<a href="#ref-eastaughffe_support_1998" role="doc-biblioref">30</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>Perceptual Cues is how easy it is to understand what is being represented. Understanding proof state is an enormous part of theorem proving. The normal solutions to understanding proof state are to offer more ways of viewing it, and ensuring easy access to these views. As of such, solutions are found in the visibility section.</p>
<h2 id="premature-commitment">Premature Commitment</h2>
<p>The problems classified under Premature Commitment are shown in Table <a href="#tbl:premature_commitment">10</a>.</p>
<div id="tbl:premature_commitment">
<table>
<caption>Table 10: Premature Commitment Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">HOL</td>
<td style="text-align: left;">Need to redesign model if proof attempt fails</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Have to apply tactics before understanding what they do</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>When an attempt to prove a theorem fails, either one of two things has happened. First, the proof the user are attempting to perform is incorrect, or the model itself is in error. The model is often in error, and as of such there is a Premature Commitment to a model before having a full understanding. Counterexample generators such as Quick Check and nitpick <span class="citation" data-cites="beckert_usability_2015 beckert_interaction_2017">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>, <a href="#ref-beckert_interaction_2017" role="doc-biblioref">16</a>]</span> for Isabelle help prevent the user from trying to prove improvable lemmas by providing the user with a counterexamples to show why their lemmas can’t be true.</p>
<p>Furthermore, tactics often need to be applied to discover what they do. Typing out this tactic is part of the exploration, and represents another premature commitment. A cheaper way to explore tactic applications were trialed with Proof previews in Coq <span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span>. These proof previews allowed the selection of the next tactic by menu, and hovering over a tactic previewed it’s application in a separate window. This was found to be helpful with users.</p>
<h2 id="progressive-evaluation">Progressive Evaluation</h2>
<p>The problems classified under Progressive Evaluation are shown in Table <a href="#tbl:progressive_evaluation">11</a>.</p>
<div id="tbl:progressive_evaluation">
<table>
<caption>Table 11: Progressive Evaluation Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">General</td>
<td style="text-align: left;">Hard to understand why proof state fails</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="hentschel_interactive_2016">[<a href="#ref-hentschel_interactive_2016" role="doc-biblioref">45</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Hard to understand why proof state fails</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_interaction_2017 beckert_interactive_2015 beckert_usability_2015">[<a href="#ref-beckert_interactive_2015" role="doc-biblioref">14</a>–<a href="#ref-beckert_interaction_2017" role="doc-biblioref">16</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Dafny</td>
<td style="text-align: left;">Hard to understand why proof state fails</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="grebing_seamless_2020">[<a href="#ref-grebing_seamless_2020" role="doc-biblioref">35</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Hard to understand why proof state fails</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="lin_understanding_2016">[<a href="#ref-lin_understanding_2016" role="doc-biblioref">55</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">General</td>
<td style="text-align: left;">Hard to understand automated tactics</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="mitsch_keymaera_2017">[<a href="#ref-mitsch_keymaera_2017" role="doc-biblioref">59</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">e General</td>
<td style="text-align: left;">Not enough feedback hinders learning</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="mitsch_keymaera_2017">[<a href="#ref-mitsch_keymaera_2017" role="doc-biblioref">59</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Lack of background automation</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">General</td>
<td style="text-align: left;">Lack of background automation</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="hunter_agent-based_2005">[<a href="#ref-hunter_agent-based_2005" role="doc-biblioref">46</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Bad feedback hinders learning</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_evaluating_2012">[<a href="#ref-beckert_evaluating_2012" role="doc-biblioref">13</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Don’t know whether an automated tactic would prove a goal</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Non reactive interfaces</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Hard to understand errors from bad inferences of types</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Performance of automatic strategy</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle,KeY</td>
<td style="text-align: left;">Difficult to understand automated strategy</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>Progressive Evaluation is the Dimension of getting appropriate feedback from the system.</p>
<p>Not understanding why proof attempts fails in a widely cited example of this. This becomes especially true when automation is added to the mix. Insight to the operation of automated tactics is missing in many ITPs. This has been suggested to be one of the largest issues with the usability of ITPs in Focus Groups <span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span>. Although there is little empirical evidence of this issue, the fact that it is so widely cited indicates importance. Solutions to this issue often resolve around providing better visibility, and are covered there.</p>
<p>Other issues include that systems with low feedback make it difficult to teach using ITPs, and that ITPs do not effectively use background processing to provide the user with feedback. One way of improving feedback is using a cache of proof state <span class="citation" data-cites="berman_development_2014 bourke_challenges_2012">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>, <a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span>. Another more novel way is to provide an agent based interaction model <span class="citation" data-cites="hunter_agent-based_2005">[<a href="#ref-hunter_agent-based_2005" role="doc-biblioref">46</a>]</span>, where the user interfaces have a "Personal assistant", who then negotiates with proof agents to help solve a particular proof. This makes best use of background processing while the user is trying to solve a problem. Neither of these have been tested with users.</p>
<p>Finally, it was mentioned in a survey of Coq users that it would be nice to know in advance whether an automated tactic could prove a goal. This would prevent further unnecessary work.</p>
<h2 id="secondary-notation">Secondary Notation</h2>
<p>Secondary Notation is the realm of comments, documentation, and even use of visual placement to convey meaning. Problems due to lack of secondary notation are usually simply because of missing features, and are therefore more naturally discussed as solutions.</p>
<p>The problems classified under Secondary Notation are shown in Table <a href="#tbl:secondary_notation">12</a>.</p>
<div id="tbl:secondary_notation">
<table>
<caption>Table 12: Secondary Notation Solutions</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Intervention</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">HOL</td>
<td style="text-align: left;">Allow notes in tree contexts</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="aitken_interactive_1998">[<a href="#ref-aitken_interactive_1998" role="doc-biblioref">3</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle,HOL</td>
<td style="text-align: left;">Allow adding notes to proof context</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_evaluating_2012">[<a href="#ref-beckert_evaluating_2012" role="doc-biblioref">13</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Add document orientated features</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="wenzel_isabelle_2011">[<a href="#ref-wenzel_isabelle_2011" role="doc-biblioref">83</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Gravity for automated lemma placement</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Deprecation tags</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Doc comments</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">HOL/CardiZ</td>
<td style="text-align: left;">Colour and low secondary notation</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="kadoda_cognitive_2000">[<a href="#ref-kadoda_cognitive_2000" role="doc-biblioref">48</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Lack of good tutorials and documentation</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Poor documentation</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_evaluating_2012">[<a href="#ref-beckert_evaluating_2012" role="doc-biblioref">13</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Better libraries and documentation</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>One improvement on secondary notations is the ability to note and label parts of proof context. Usually, proof context is boxed off and cannot be documented other than basic comments. Interestingly, although this feature is cited multiple times. It remains, to the best of my knowledge, unimplemented, and as with the rest of the solutions in this category, untested.</p>
<p>Document oriented proof organization tries to make each theory readable both to a human and to a computer, and involves allowing linking to external theories, websites, diagrams and other features all in the prover editor. This is commonly done with web interfaces controlled by ITP code. This method has not been investigated as being beneficial, but Matita itself was built to support this style of interaction.</p>
<p>Features such as deprecation tags, doc comments and automatic naming of lemmas frequently showed up. These indicate that it is important for the user to break out and write hints to help themselves and others navigate their code. These have been implemented in some provers, but again, have not been tested.</p>
<p>Finally, a very common issue with ITPs is the lack of tutorials and documentation, particularly around library functionality. This is remarkably important, regardless of what the prover is.</p>
<h2 id="viscosity">Viscosity</h2>
<p>The problems classified under Viscosity are shown in Table <a href="#tbl:viscosity">13</a>.</p>
<div id="tbl:viscosity">
<table>
<caption>Table 13: Viscosity Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Messy Downwards compatibility</td>
<td style="text-align: left;">Focus Groups</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">No support for proof refactoring</td>
<td style="text-align: left;">Focus Groups</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Direct Manipulation</td>
<td style="text-align: left;">Tedious Interactions</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="grebing_usability_2020 beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>, <a href="#ref-grebing_usability_2020" role="doc-biblioref">36</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">General</td>
<td style="text-align: left;">Hard to make effective use of large library</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="asperti_considerations_2010 tassi_interactive_2008">[<a href="#ref-asperti_considerations_2010" role="doc-biblioref">6</a>, <a href="#ref-tassi_interactive_2008" role="doc-biblioref">80</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Tacticals difficult to write</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="becker_lassie_2021">[<a href="#ref-becker_lassie_2021" role="doc-biblioref">12</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Have to update proofs once definition changes</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="ringer_replica_2020">[<a href="#ref-ringer_replica_2020" role="doc-biblioref">71</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Proof renaming and refactoring is tedious</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="ringer_replica_2020">[<a href="#ref-ringer_replica_2020" role="doc-biblioref">71</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Large proof scripts require too long to recompile</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="barras_asynchronous_2015">[<a href="#ref-barras_asynchronous_2015" role="doc-biblioref">10</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Isabelle</td>
<td style="text-align: left;">Large proof scripts require too long to recompile</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="wenzel_asynchronous_2014">[<a href="#ref-wenzel_asynchronous_2014" role="doc-biblioref">82</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Difficult to select terms</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Unnecessary re-running of proofs</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Slow for large proofs</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="roe_coqpie_2016">[<a href="#ref-roe_coqpie_2016" role="doc-biblioref">72</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Change in lemma requires change in proof</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="roe_coqpie_2016">[<a href="#ref-roe_coqpie_2016" role="doc-biblioref">72</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Bad change management</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_evaluating_2012">[<a href="#ref-beckert_evaluating_2012" role="doc-biblioref">13</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Bad Automated proof performance</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_evaluating_2012">[<a href="#ref-beckert_evaluating_2012" role="doc-biblioref">13</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Hard to decompose proof</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_interactive_2015">[<a href="#ref-beckert_interactive_2015" role="doc-biblioref">14</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>Viscosity is the Cognitive Dimension of the ease of changing the state of the programs.</p>
<p>One source of viscosity is simply performance. As automatic strategies get more complicated, their performance becomes important for them to be useful to the user. This has been suggested by focus groups and in surveys. This becomes a particularly difficult problem especially for larger systems. Attempts to improve performance have been done by asynchronously loading only required parts of the proof in Coq <span class="citation" data-cites="barras_asynchronous_2015">[<a href="#ref-barras_asynchronous_2015" role="doc-biblioref">10</a>]</span> and Isabelle <span class="citation" data-cites="wenzel_asynchronous_2014">[<a href="#ref-wenzel_asynchronous_2014" role="doc-biblioref">82</a>]</span>. Improvements to performance of automatic strategies will always be an improvement <span class="citation" data-cites="bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>]</span>, including making better use of the library <span class="citation" data-cites="tassi_interactive_2008 asperti_considerations_2010">[<a href="#ref-asperti_considerations_2010" role="doc-biblioref">6</a>, <a href="#ref-tassi_interactive_2008" role="doc-biblioref">80</a>]</span>.</p>
<p>A second source is the need to make trivial interactions when making small changes. For instance, the renaming of a lemma require needing to go through several files to find where to change the identifier. Messy downwards compatibility, changing definitions, and lack of refactoring are all examples of this. These are usually addressed by refactoring tools that have been suggested as necessary <span class="citation" data-cites="ringer_replica_2020 bourke_challenges_2012">[<a href="#ref-bourke_challenges_2012" role="doc-biblioref">22</a>, <a href="#ref-ringer_replica_2020" role="doc-biblioref">71</a>]</span> and implemented in some IDEs such as CoqPIE <span class="citation" data-cites="roe_coqpie_2016">[<a href="#ref-roe_coqpie_2016" role="doc-biblioref">72</a>]</span>. These solutions have not been tested with users.</p>
<p>The third is simply interactions that are tedious and error prone. This is more common in direct manipulation theorem provers such as KeY. No solutions have been suggested for this problem.</p>
<p>Finally, the fourth source of viscosity is clunky syntax, such as the need to explain selections to the theorem prover. Selections are a common issue when describing the part of the goal that the user wants to rewrite. This part might be complicated, but has to be represented textually. This has served as a challenge for ITP designers. Selections using patterns has been implemented in Matita <span class="citation" data-cites="zacchiroli_user_2007 asperti_user_2007">[<a href="#ref-asperti_user_2007" role="doc-biblioref">7</a>, <a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span> to address this pain point.</p>
<h2 id="visibility">Visibility</h2>
<p>The problems classified under Visibility are shown in Table <a href="#tbl:visibility">14</a>.</p>
<div id="tbl:visibility">
<table>
<caption>Table 14: Visibility Problems</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Theorem prover</th>
<th style="text-align: left;">Problems</th>
<th style="text-align: left;">Discovered</th>
<th style="text-align: left;">citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Proof tree too detailed</td>
<td style="text-align: left;">Focus Groups</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Textual</td>
<td style="text-align: left;">Limited insight to automated tactics</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="grebing_usability_2020">[<a href="#ref-grebing_usability_2020" role="doc-biblioref">36</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">HOL</td>
<td style="text-align: left;">Hard to understand proof tree</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="aitken_interactive_1998">[<a href="#ref-aitken_interactive_1998" role="doc-biblioref">3</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">HOL</td>
<td style="text-align: left;">Allow showing and hiding of proof contexts</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="aitken_interactive_1998">[<a href="#ref-aitken_interactive_1998" role="doc-biblioref">3</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Cannot see intermediate proof states</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="zacchiroli_user_2007">[<a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Difficult to see structure of proof tree</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Cannot see the relation between subgoals</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Coq</td>
<td style="text-align: left;">Cannot quickly see type or simplification of term</td>
<td style="text-align: left;">Survey</td>
<td style="text-align: left;"><span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">KeY</td>
<td style="text-align: left;">Bad presentation of incomplete proofs</td>
<td style="text-align: left;">Suggested</td>
<td style="text-align: left;"><span class="citation" data-cites="beckert_evaluating_2012">[<a href="#ref-beckert_evaluating_2012" role="doc-biblioref">13</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<p>Visibility was a commonly cited issue with interactive theorem provers.</p>
<p>The Cognitive Dimension of visibility has to do with being able to how information can be identified and accessible to the user. For the case of interactive theorem provers, there were cases where theorem provers show too much or too little information.</p>
<p>Direct manipulation theorem provers such as KeY were found to show too much information in the proof tree, which overwhelms the user trying to work out why a proof attempt has failed. The simplest solution to this is to only show information needed <span class="citation" data-cites="eastaughffe_support_1998">[<a href="#ref-eastaughffe_support_1998" role="doc-biblioref">30</a>]</span> and allow the opening and closing of views <span class="citation" data-cites="aitken_interactive_1998">[<a href="#ref-aitken_interactive_1998" role="doc-biblioref">3</a>]</span>. However, some IDEs (such as CoqIDE) come without a proof tree. These have been considered helpful <span class="citation" data-cites="berman_development_2014 aitken_interactive_1998">[<a href="#ref-aitken_interactive_1998" role="doc-biblioref">3</a>, <a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span> and have been implemented with Traf <span class="citation" data-cites="kawabata_traf_2018">[<a href="#ref-kawabata_traf_2018" role="doc-biblioref">52</a>]</span></p>
<p>In contrast, it’s also been claimed that there is a lack of visibility of the proof state, particularly intermediate proof states within textual theorem provers. The lack of visibility is often to do with intermediate proof states. An intermediate proof state is the state that a proof is in before the full completion of a tactic, and can be used to determine how a tactic got to a particular proof state. Understanding these intermediate proof states is important in understanding the process of automatic theorem provers and the current state. Viewing intermediate proof states is not possible with Isabelle/HOL or Coq. In fact, it is not even possible to investigate the inside of tacticals making it even more difficult to understand intuitively a proof. The tactical problem has been resolved by only using a subset of tacticals with Matita’s Tinycals <span class="citation" data-cites="asperti_user_2007 zacchiroli_user_2007">[<a href="#ref-asperti_user_2007" role="doc-biblioref">7</a>, <a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span>. KeYmaera X also offers traceability with automatic tactics, allowing insight to the operations they performed <span class="citation" data-cites="mitsch_keymaera_2017">[<a href="#ref-mitsch_keymaera_2017" role="doc-biblioref">59</a>]</span>.</p>
<p>In one of the only empirical tests of two different user interfaces, an interface akin to a symbolic debugger is compared against the standard interface of KeY <span class="citation" data-cites="hentschel_integrating_2016 hentschel_empirical_2016 hentschel_interactive_2016">[<a href="#ref-hentschel_integrating_2016" role="doc-biblioref">43</a>–<a href="#ref-hentschel_interactive_2016" role="doc-biblioref">45</a>]</span>. The symbol debugger was found to be easier to use. The interfaces are very different, and it could be for a variety of reasons. One such reason is that the interface of a symbolic debugger maps better onto the context of source code, and offers visibility of that connection. Offering different ways of viewing and interacting with proof state has been suggested as a way forward in the usability of ITPs <span class="citation" data-cites="eastaughffe_support_1998 grebing_seamless_2020">[<a href="#ref-eastaughffe_support_1998" role="doc-biblioref">30</a>, <a href="#ref-grebing_seamless_2020" role="doc-biblioref">35</a>]</span>.</p>
<p>Diagrammatic representations of proof is an alternative way of proving theorems, as demonstrated with iCon <span class="citation" data-cites="shams_accessible_2018">[<a href="#ref-shams_accessible_2018" role="doc-biblioref">76</a>]</span> and Proof Transitions in CoqEdit <span class="citation" data-cites="berman_development_2014">[<a href="#ref-berman_development_2014" role="doc-biblioref">18</a>]</span>. This has not been tested empirically against other ITPs</p>
<h2 id="analysis">Analysis</h2>
<p>Many problems were identified. A summary of the problem is tabulated in Figure <a href="#fig:usability_issues">3</a>.</p>
<figure>
<img src="./Images/MyProblem.png" id="fig:usability_issues" alt="Figure 3: Identified Usability Issues" /><figcaption aria-hidden="true">Figure 3: Identified Usability Issues</figcaption>
</figure>
<p>This analysis finds that although many issues were identified, there is very little empirical research on these problems. This is probably due to the difficulty in recruiting expert participants to these studies, and the small size of the field.</p>
<p>An empirical analysis of all of these problems is well and truly outside the scope of this thesis. The task at hand is to now select problems that can be addressed.</p>
<p>The first thing to consider is that we are creating a living review. Many of the usability issues that arose have a strong human component. For instance, “Hard to predict the results of tactics” would be very difficult to evaluate without performing a usability test. If we were to include a measure within the living review that required the conducting of a usability test, the usability test would need to be run on a periodic basis to keep it up to date with the current state of technology. This is highly undesirable, as such a project would be extremely time consuming and expensive, and would require a time and money investment for years after this thesis is published.</p>
<p>To address this, we restrict this thesis to usability issues that can be determined to exist without the highly expensive intervention of a user. This leaves the following options:</p>
<ul>
<li>Scope of Library</li>
<li>Math Notation support</li>
<li>Counterexamples</li>
<li>Performance</li>
</ul>
<p>All these issues beside performance are within the scope of our living review. Although creating a living review for ITP performance that automatically updates is technically feasible, we determined that this was not a usability problem of interest in comparison to the large amount of effort and money (setting up a list of standard activities, setting up of standardised hardware, running programs in test harnesses) required to include performance the review’s scope.</p>
<h1 id="sec:results">Results</h1>
<p>In this section, we discuss in detail the living review that we have contributed. This section is only a static snapshot of the review at its current stage. The full living review is available online and will be fully up to date. Therefore, it should be noted that the living review itself contains all the information found in this section and more. If you wish to view the results as it is up to date, then we invite you to look through the online widget.</p>
As you are viewing this via the web, the widget is embedded below for you to explore:
<div id="itps">

</div>
<p>The source code for this thesis, the widget, and all the code behind it are also available on GitHub at <a href="https://github.com/Hazelfire/thesis">https://github.com/Hazelfire/thesis</a>. What follows is a snapshot of the findings in the review.</p>
<p>The following 17 ITPs were included in the review: ACL2 <span class="citation" data-cites="ACL2">[<a href="#ref-ACL2" role="doc-biblioref">51</a>]</span>, Agda <span class="citation" data-cites="Agda">[<a href="#ref-Agda" role="doc-biblioref">64</a>]</span>, Atelier B <span class="citation" data-cites="Atelier_B">[<a href="#ref-Atelier_B" role="doc-biblioref">25</a>]</span>, Coq <span class="citation" data-cites="Coq">[<a href="#ref-Coq" role="doc-biblioref">19</a>]</span>, Getfol <span class="citation" data-cites="Getfol">[<a href="#ref-Getfol" role="doc-biblioref">33</a>]</span>, HOL Light <span class="citation" data-cites="HOL_Light">[<a href="#ref-HOL_Light" role="doc-biblioref">41</a>]</span>, HOL4 <span class="citation" data-cites="HOL4">[<a href="#ref-HOL4" role="doc-biblioref">78</a>]</span>, Isabelle <span class="citation" data-cites="Isabelle">[<a href="#ref-Isabelle" role="doc-biblioref">68</a>]</span>, JAPE <span class="citation" data-cites="JAPE">[<a href="#ref-JAPE" role="doc-biblioref">21</a>]</span>, LEO-II <span class="citation" data-cites="LEO-II">[<a href="#ref-LEO-II" role="doc-biblioref">17</a>]</span>, Lean <span class="citation" data-cites="Lean">[<a href="#ref-Lean" role="doc-biblioref">61</a>]</span>, Metamath <span class="citation" data-cites="Metamath">[<a href="#ref-Metamath" role="doc-biblioref">65</a>]</span>, Mizar <span class="citation" data-cites="Mizar">[<a href="#ref-Mizar" role="doc-biblioref">34</a>]</span>, PVS <span class="citation" data-cites="PVS">[<a href="#ref-PVS" role="doc-biblioref">73</a>]</span>, RedPRL <span class="citation" data-cites="RedPRL">[<a href="#ref-RedPRL" role="doc-biblioref">5</a>]</span>, Twelf <span class="citation" data-cites="Twelf">[<a href="#ref-Twelf" role="doc-biblioref">69</a>]</span>, and Z/EVES <span class="citation" data-cites="Z/EVES">[<a href="#ref-Z/EVES" role="doc-biblioref">74</a>]</span>.</p>
<p>The results are split into three sections. In Section <a href="#sec:math_libraries">4.1</a>, results about the state and scope of mathematical libraries of ITPs are discussed. In Section <a href="#sec:counterexamples">4.2</a> results about the support of Counterexample generators are covered. Finally, in Section <a href="#sec:math_notation">4.3</a> and results about mathematical notation support are covered.</p>
<h2 id="sec:math_libraries">Mathematical Libraries</h2>
<p>This section details results about the distribution of mathematical topics currently covered by ITPs, as of 28 October 2021. All findings, including the dataset of classified modules, can be viewed and downloaded in the up to date form by viewing the review online.</p>
<p>The methodology for this section has been laid out in Section <a href="#sec:scope_of_library_meth">2.2.2</a>.</p>
<h3 id="step-1-identifying-libraries">Step 1: Identifying Libraries</h3>
<p>This section corresponds to the section laid out in Section <a href="#sec:identifying_math_lib_meth">2.2.2.1</a></p>
<p>13 mathematical libraries were covered in this analysis. They are detailed in Table <a href="#tbl:libraries">15</a>.</p>
<p>Twelf was excluded due to not proving any mathematical theorems within its library, failing IC1.</p>
<p>Getfol and RedPRL failed to meet IC2, in having small libraries with only 1372 and 2680 lines of proof code respectively.</p>
<p>LEO-II and Z/EVES do not have standard libraries.</p>
<h3 id="step-2-collecting-modules">Step 2: Collecting modules</h3>
<p>As per our methodology in section Section <a href="#sec:collecting_modules_meth">2.2.2.2</a>, we must now chose what we mean by a module for comparison. What we chose as a module is listed in Table <a href="#tbl:libraries">15</a> for each ITP.</p>
<p>We chose the library sizes based on the methodology in Section <a href="#sec:collecting_modules_meth">2.2.2.2</a>.</p>
<div id="tbl:libraries">
<table>
<caption>Table 15: Libraries covered in the living review</caption>
<colgroup>
<col style="width: 9%" />
<col style="width: 25%" />
<col style="width: 30%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Library</th>
<th>Type</th>
<th>Module Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ACL2</td>
<td><a href="https://github.com/acl2/acl2/tree/master/books">Community Books</a></td>
<td>packages</td>
<td>a community book, such as acl2ls or data-structures</td>
</tr>
<tr class="even">
<td>Agda</td>
<td><a href="https://wiki.portal.chalmers.se/agda/Main/Libraries">Community Libraries</a></td>
<td>packages</td>
<td>a submission such as AoPA or DTGP</td>
</tr>
<tr class="odd">
<td>Agda</td>
<td><a href="https://github.com/agda/agda-stdlib">Standard Library</a></td>
<td>small</td>
<td>a top level module, such as Data or Algebra</td>
</tr>
<tr class="even">
<td>Coq</td>
<td><a href="https://coq.inria.fr/library/index.html">Standard Library</a></td>
<td>small</td>
<td>a top level module, such as Init or Arith</td>
</tr>
<tr class="odd">
<td>Coq</td>
<td><a href="https://coq.inria.fr/opam/www/">Packages</a></td>
<td>packages</td>
<td>a package</td>
</tr>
<tr class="even">
<td>HOL Light</td>
<td><a href="https://github.com/jrh13/hol-light">HOL Light Library</a></td>
<td>large</td>
<td>a second level module, such as Library/analysis.ml or Multivariate/clifford.ml</td>
</tr>
<tr class="odd">
<td>HOL4</td>
<td><a href="https://github.com/HOL-Theorem-Prover/HOL/tree/develop/src">HOL4 Library</a></td>
<td>small</td>
<td>a top level module, such as bool or topology</td>
</tr>
<tr class="even">
<td>Isabelle</td>
<td><a href="https://isabelle.in.tum.de/dist/library/">Core Libraries</a></td>
<td>large</td>
<td>a session, such as HOL/HOL-Algebra</td>
</tr>
<tr class="odd">
<td>Isabelle</td>
<td><a href="https://www.isa-afp.org/">Archive of Formal Proofs</a></td>
<td>packages</td>
<td>a submission</td>
</tr>
<tr class="even">
<td>Lean</td>
<td><a href="https://leanprover-community.github.io/mathlib-overview.html">Lean Mathematical Library</a></td>
<td>large</td>
<td>a second level module, such as algebra.algebra or probability.distribution</td>
</tr>
<tr class="odd">
<td>Metamath</td>
<td><a href="http://us.metamath.org/mpeuni/mmset.html">Metamath Library</a></td>
<td>small</td>
<td>a "part", such as "ZF SET THEORY", or one of the smaller theories, such as "Higher Order Logic"</td>
</tr>
<tr class="even">
<td>Mizar</td>
<td><a href="http://www.mizar.org/library/">Mizar Mathematical Library</a></td>
<td>package</td>
<td>a submission, such as abian of aff_2</td>
</tr>
<tr class="odd">
<td>PVS</td>
<td><a href="https://github.com/nasa/pvslib">NASA PVS Library of Formal Developments</a></td>
<td>packages</td>
<td>a module, such as algebra or analysis</td>
</tr>
</tbody>
</table>
</div>
<h3 id="step-3-classifying-modules">Step 3: Classifying modules</h3>
<p>From these libraries, 5581 math modules were collected libraries. All of these modules were classified according to MSC2020. They are presented in Figure <a href="#fig:total_itp_modules">4</a>.</p>
<figure>
<img src="./Images/ITPTotal.png" id="fig:total_itp_modules" alt="Figure 4: Amount of modules found in each ITP" /><figcaption aria-hidden="true">Figure 4: Amount of modules found in each ITP</figcaption>
</figure>
<p>In descending order of the amount of total mathematical modules, a description of the classification for each ITP is given:</p>
<p><strong>Mizar - Mizar Mathematical Library</strong>: Has a total of 1383 modules. Of these modules, 52 modules were excluded. Including 16 modules were excluded for being a utility (EC1). 915 modules were verified into categories and 416 require a professional mathematician to properly categorise.</p>
<p><strong>ACL2 - Community Books</strong>: Has a total of 873 modules. Of these modules, 616 modules were excluded. Including 448 modules were excluded for being a utility (EC1), 53 modules were excluded for being only documentation (EC3), and 26 modules were excluded for being deprecated (EC4). 245 modules were verified into categories and 12 require a professional mathematician to properly categorise.</p>
<p><strong>Lean - Lean Mathematical Library</strong>: Has a total of 739 modules. Of these modules, 159 modules were excluded. Including 150 modules were excluded for being a utility (EC1), one module was excluded for being only documentation (EC3), and 6 modules were excluded for being deprecated (EC4). 269 modules were verified into categories and 311 require a professional mathematician to properly categorise.</p>
<p><strong>HOL4 - HOL4 Library</strong>: Has a total of 734 modules. Of these modules, 512 modules were excluded. Including 294 modules were excluded for being a utility (EC1) and one module was excluded for being only documentation (EC3). 191 modules were verified into categories and 31 require a professional mathematician to properly categorise.</p>
<p><strong>Isabelle - Archive of Formal Proofs</strong>: Has a total of 611 modules. Of these modules, 3 modules were excluded. Including 3 modules were excluded for being a utility (EC1). 495 modules were verified into categories and 113 require a professional mathematician to properly categorise.</p>
<p><strong>HOL Light - HOL Light Library</strong>: Has a total of 400 modules. Of these modules, 145 modules were excluded. Including 71 modules were excluded for being a utility (EC1) and 25 modules were excluded for being only documentation (EC3). 166 modules were verified into categories and 89 require a professional mathematician to properly categorise.</p>
<p><strong>Coq - Packages</strong>: Has a total of 396 modules. Of these modules, 119 modules were excluded. Including 114 modules were excluded for being a utility (EC1), one module was excluded for being only documentation (EC3), and 3 modules were excluded for being deprecated (EC4). 214 modules were verified into categories and 63 require a professional mathematician to properly categorise.</p>
<p><strong>Metamath - Metamath Library</strong>: Has a total of 171 modules. Of these modules, 60 modules were excluded. Including 42 modules were excluded for being a utility (EC1), 2 modules were excluded for being only documentation (EC3), and 16 modules were excluded for being deprecated (EC4). 72 modules were verified into categories and 39 require a professional mathematician to properly categorise.</p>
<p><strong>Isabelle - Core Libraries</strong>: Has a total of 123 modules. Of these modules, 25 modules were excluded. Including one module was excluded for being a utility (EC1) and 18 modules were excluded for being only documentation (EC3). 73 modules were verified into categories and 24 require a professional mathematician to properly categorise.</p>
<p><strong>PVS - NASA PVS Library of Formal Developments</strong>: Has a total of 54 modules. Of these modules, 12 modules were excluded. Including 11 modules were excluded for being a utility (EC1) and one module was excluded for being only documentation (EC3). 41 modules were verified into categories and 1 require a professional mathematician to properly categorise.</p>
<p><strong>Agda - Community Libraries</strong>: Has a total of 43 modules. Of these modules, 19 modules were excluded. Including 13 modules were excluded for being a utility (EC1) and 2 modules were excluded for being only documentation (EC3). 21 modules were verified into categories and 3 require a professional mathematician to properly categorise.</p>
<p><strong>Coq - Standard Library</strong>: Has a total of 36 modules. Of these modules, 7 modules were excluded. Including 7 modules were excluded for being a utility (EC1). 27 modules were verified into categories and 2 require a professional mathematician to properly categorise.</p>
<p><strong>Agda - Standard Library</strong>: Has a total of 18 modules. Of these modules, 8 modules were excluded. Including 8 modules were excluded for being a utility (EC1). 9 modules were verified into categories and 1 require a professional mathematician to properly categorise.</p>
<p>It was found that some libraries were clear outliers in mathematical scope covered. Those libraries were Coq, HOL Light, Isabelle, Lean, and Mizar. It would be difficult to justify use of other theorem provers as a mathematician getting into the field.</p>
<p>HOL4, HOL Light and ACL2 have a lot of excluded modules due to having many utilities available for the user. For instance, in HOL Light allows you to write proofs in a declarative Mizar style, and has a module for this. This is not relevant for determining mathematical scope.</p>
<figure>
<img src="./Images/MathClassification.png" id="fig:math_classifications" alt="Figure 5: Math Package classifications, as of 28 October 2021" /><figcaption aria-hidden="true">Figure 5: Math Package classifications, as of 28 October 2021</figcaption>
</figure>
<p>The chart in Figure <a href="#fig:math_classifications">5</a> shows which verified top level MSC Classifications these modules were sorted into as of 28 October 2021. Each column represents a top level classification of a mathematical topic from MSC2020, sorted by by the amount of total modules in each classification. Each colour represents modules from a different ITP.</p>
<p>This chart was created using Vega-Lite <span class="citation" data-cites="Vega-Lite">[<a href="#ref-Vega-Lite" role="doc-biblioref">75</a>]</span> a chart visualisation framework. It is reproduced in the living review where it is fully up to date and is further interactive, showing the exact modules counts when hovering with a mouse.</p>
<p>The chart represents the mathematical scope of each of the libraries. If a particular field has more modules, it represents a larger availability of prior work to build upon when developing new proofs, therefore less working from the ground up.</p>
<p><strong>Computer science (68-XX)</strong>: Had a total of 978 modules. The ITPs with the most packages in this category were <em>Isabelle</em> with 323 modules, <em>HOL4</em> with 158 modules, and <em>Coq</em> with 146 modules. The most popular second level MSC classifications were <em>Theory of data</em> (68Pxx) with 320 modules, <em>Theory of computing</em> (68Qxx) with 252 modules, and <em>Theory of software</em> (68Nxx) with 151 modules. Computer Science was clearly the most popular category, mainly because ITPs like ACL2, Isabelle, HOL4 and Coq are all mainly built for the purpose of verifying software. There was a large amount of data structures of all kinds created to reason about programs. Even Mizar, a usually mathematical ITP, has several modules dedicated to the verification of software.</p>
<p><strong>Mathematical logic and foundations (03-XX)</strong>: Had a total of 548 modules. The ITPs with the most packages in this category were <em>Mizar</em> with 188 modules, <em>Isabelle</em> with 113 modules, and <em>Coq</em> with 53 modules. The most popular second level MSC classifications were <em>Set theory</em> (03Exx) with 183 modules, <em>General logic</em> (03Bxx) with 180 modules, and <em>Proof theory and constructive mathematics</em> (03Fxx) with 56 modules. Mathematical Logic and Foundations was common because often ITPs would start developing their libraries through laying the foundations. However, some ITPs such as Mizar have large amounts of contributions on topics such as fuzzy logic, which does not neccesarily make up its foundation but is still within this category.</p>
<p><strong>Number theory (11-XX)</strong>: Had a total of 209 modules. The ITPs with the most packages in this category were <em>Mizar</em> with 63 modules, <em>HOL Light</em> with 46 modules, and <em>Isabelle</em> with 38 modules. The most popular second level MSC classifications were <em>Elementary number theory </em> (11Axx) with 72 modules and <em>Sequences and sets</em> (11Bxx) with 19 modules. Number Theory consistently had a large amount of modules from most ITPs. Elementary Number theory made up the majority of this category, mainly modular arithmetic, distribution of primes and primality checking.</p>
<p><strong>Real functions (26-XX)</strong>: Had a total of 186 modules. The ITPs with the most packages in this category were <em>Mizar</em> with 89 modules, <em>HOL Light</em> with 36 modules, and <em>Metamath</em> with 21 modules. The most popular second level MSC classifications were <em>Functions of one variable</em> (26Axx) with 90 modules and <em>Functions of several variables</em> (26Bxx) with 34 modules. Real Functions covers topics often considered to be part of real analysis. This classification has a strong presence in Mizar, where a large amount of real analysis is covered. But also HOL Light, which sports a strong multivariate library.</p>
<p><strong>General topology (54-XX)</strong>: Had a total of 185 modules. The ITPs with the most packages in this category were <em>Mizar</em> with 121 modules, <em>Lean</em> with 46 modules, and <em>HOL Light</em> with 6 modules. The most popular second level MSC classifications were <em>Topological spaces with richer structures</em> (54Exx) with 24 modules and <em>Fairly general properties of topological spaces</em> (54Dxx) with 20 modules. Topology made up a large amount of modules. Mizar definitely dominated this space, and discusses topology widely.</p>
<p><strong>Order, lattices, ordered algebraic structures (06-XX)</strong>: Had a total of 179 modules. The ITPs with the most packages in this category were <em>Mizar</em> with 101 modules, <em>Lean</em> with 50 modules, and <em>Isabelle</em> with 12 modules. The most popular second level MSC classifications were <em>Lattices </em> (06Bxx) with 60 modules and <em>Ordered structures</em> (06Fxx) with 19 modules. Orders was covered widely, mainly in discussion with lattices. Mizar has a large amount of modules dedicated to formalising continuous lattices, which are then used in the context of Domain Theory.</p>
<p><strong>Combinatorics (05-XX)</strong>: Had a total of 147 modules. The ITPs with the most packages in this category were <em>Isabelle</em> with 54 modules, <em>Mizar</em> with 46 modules, and <em>HOL Light</em> with 18 modules. The most popular second level MSC classifications were <em>Graph theory </em> (05Cxx) with 93 modules and <em>Enumerative combinatorics </em> (05Axx) with 31 modules. There were a large amount of combinatorics modules, mainly from graph theory. Isabelle here has the most packages, using graph theory mainly for the purpose of verifying graph algorithms.</p>
<p><strong>Category theory; homological algebra (18-XX)</strong>: Had a total of 137 modules. The ITPs with the most packages in this category were <em>Lean</em> with 70 modules, <em>Mizar</em> with 41 modules, and <em>Isabelle</em> with 12 modules. The most popular second level MSC classifications were <em>General theory of categories and functors</em> (18Axx) with 38 modules and <em>Categories and theories</em> (18Cxx) with 9 modules. Category theory is often in the context of functional programming and controlling effects. Haskell has popularized the use of monads for controlling effects. ITPs such as Lean reimplement those concepts in their ITPs.</p>
<p><strong>Commutative algebra (13-XX)</strong>: Had a total of 135 modules. The ITPs with the most packages in this category were <em>Lean</em> with 71 modules, <em>Mizar</em> with 42 modules, and <em>Isabelle</em> with 8 modules. The most popular second level MSC classifications were <em>Theory of modules and ideals in commutative rings</em> (13Cxx) with 22 modules and <em>General commutative ring theory</em> (13Axx) with 18 modules. Discussion of Commutative Algebra was mainly restricted to ITPs interested in proving math theorems, such as Mizar or Lean. Lean has a top level module entirely on ring theory.</p>
<p><strong>Geometry (51-XX)</strong>: Had a total of 135 modules. The ITPs with the most packages in this category were <em>Mizar</em> with 79 modules, <em>HOL Light</em> with 25 modules, and <em>Isabelle</em> with 14 modules. The most popular second level MSC classifications were <em>Real and complex geometry</em> (51Mxx) with 42 modules and <em>Analytic and descriptive geometry</em> (51Nxx) with 24 modules. Geometry was common among most theroem provers, with Mizar having a large amount of module about Affine Geometry.</p>
<h2 id="sec:counterexamples">Counterexample generators</h2>
<p>Counterexample generators have been suggested to be beneficial in helping users understand the proof state they they were in <span class="citation" data-cites="beckert_usability_2015">[<a href="#ref-beckert_usability_2015" role="doc-biblioref">15</a>]</span>.</p>
<p>This living review covers 3 counter example generators. These counterexamples generators were;</p>
<p><strong>Nitpick</strong> <span class="citation" data-cites="Nitpick">[<a href="#ref-Nitpick" role="doc-biblioref">20</a>]</span>: Nitpick is a counterexample generator for Isabelle/HOL. It is fundementally a model finder and works by using the relational model finder KodKod <span class="citation" data-cites="KodKod">[<a href="#ref-KodKod" role="doc-biblioref">81</a>]</span> as a backend. Model finders are akin to SAT solvers, in that they work by attempting to find a collection of values that satisfy a given statement. Nitpick uses model finders in order to find possible counterexamples. Nitpick also outperforms QuickCheck. It has support for Isabelle.</p>
<p><strong>Nunchaku</strong> <span class="citation" data-cites="NanchakuLean NanchakuCoq">[<a href="#ref-NanchakuCoq" role="doc-biblioref">26</a>, <a href="#ref-NanchakuLean" role="doc-biblioref">67</a>]</span>: Nunchaku is a counterexample generator intended to be the successor of Nitpick. One of its main advantages over Nitpick is that it’s designed to work with multiple different frontends (ITPs), as well as different backends, such as CVC4 <span class="citation" data-cites="CVC4">[<a href="#ref-CVC4" role="doc-biblioref">11</a>]</span>. It has support for Isabelle, Coq, and Lean.</p>
<p><strong>QuickCheck</strong> <span class="citation" data-cites="QuickChick QuickCheckAgda PVSQuickCheck QuickCheckIsabelle DoubleCheck">[<a href="#ref-QuickCheckIsabelle" role="doc-biblioref">23</a>, <a href="#ref-QuickChick" role="doc-biblioref">28</a>, <a href="#ref-QuickCheckAgda" role="doc-biblioref">29</a>, <a href="#ref-DoubleCheck" role="doc-biblioref">31</a>, <a href="#ref-PVSQuickCheck" role="doc-biblioref">66</a>]</span>: QuickCheck is a type of property based random testing tool. It’s not a particular piece of software but has many implementations in many languages. It works by specifying a property that you want to test about a system, and QuickCheck attempts to falsify that the property holds by giving attempting checking to see if there are counterexamples. Often QuickCheck is simply used for sotware testing, as it is in Haskell <span class="citation" data-cites="QuickCheckHaskell">[<a href="#ref-QuickCheckHaskell" role="doc-biblioref">24</a>]</span>. However, in the context of theorem provers, it can be used to find counterexamples to statement you might wish to prove. It has support for Agda, Isabelle, PVS, Coq, and ACL2.</p>
<p>This leaves Atelier B, Getfol, HOL Light, HOL4, JAPE, LEO-II, Metamath, Mizar, RedPRL, Twelf, and Z/EVES not having counter example generators.</p>
<h2 id="sec:math_notation">Math Notation in libraries</h2>
<p>Support of mathematical notation was suggested <span class="citation" data-cites="berman_development_2014">[<a href="#ref-zacchiroli_user_2007" role="doc-biblioref">87</a>]</span>.</p>
<p>The ITPs that use math notation include:</p>
<p><strong>Agda</strong>: Agda has support for Unicode characters. And uses Unicode characters in its math library. This often requires special editor integrations to input the Unicode characters. Figure <a href="#fig:agda_code">6</a> Shows an example of Agda code</p>
<figure>
<img src="Images/Notation/Agda.png" id="fig:agda_code" alt="Figure 6: Agda source code example, from standard library, Category.Monad.State" /><figcaption aria-hidden="true">Figure 6: Agda source code example, from standard library, Category.Monad.State</figcaption>
</figure>
<p><strong>Isabelle</strong>: Isabelle uses LaTeX math commands to represent math notation. This is strong supported within the IDE. The saved plaintext is chown in Figure <a href="#fig:isabelle_raw">7</a>.</p>
<figure>
<img src="Images/Notation/IsabelleRaw.png" id="fig:isabelle_raw" alt="Figure 7: Isabelle source code raw, from core libraries, HOL/Archimedian_Field.thy" /><figcaption aria-hidden="true">Figure 7: Isabelle source code raw, from core libraries, HOL/Archimedian_Field.thy</figcaption>
</figure>
<p>Whereas the rendered version shown in Figure <a href="#fig:isabelle_rendered">8</a>.</p>
<figure>
<img src="Images/Notation/IsabelleRender.png" id="fig:isabelle_rendered" alt="Figure 8: Isabelle source code rendered, from core libraries, HOL/Archimedian_Field.thy" /><figcaption aria-hidden="true">Figure 8: Isabelle source code rendered, from core libraries, HOL/Archimedian_Field.thy</figcaption>
</figure>
<p><strong>Lean</strong>: Lean has allows representing math notation using Unicode. As shown in Figure <a href="#fig:lean_example">9</a>.</p>
<figure>
<img src="Images/Notation/LeanUnicode.png" id="fig:lean_example" alt="Figure 9: Lean source code rendered, from mathlib, category.monad.basic" /><figcaption aria-hidden="true">Figure 9: Lean source code rendered, from mathlib, category.monad.basic</figcaption>
</figure>
<p><strong>Z/EVES</strong>: Z/EVES uses LaTeX commands to prove propositions. The interface, much like Isabelle, allows the user to press buttons on the interface to input notation. As shown in Figure <a href="#fig:zeves_example">10</a>.</p>
<figure>
<img src="Images/Notation/Zeves.png" id="fig:zeves_example" alt="Figure 10: Z/EVES notation support" /><figcaption aria-hidden="true">Figure 10: Z/EVES notation support</figcaption>
</figure>
<p>The ITPs in this study without math notation are ACL2, Atelier B, Coq, Getfol, HOL Light, HOL4, JAPE, LEO-II, Metamath, Mizar, PVS, RedPRL, and Twelf. These theorem provers may also be improved with math notation support.</p>
<p>The ITPs in this study without math notation are ACL2, Atelier B, Coq, Getfol, HOL Light, HOL4, JAPE, LEO-II, Metamath, Mizar, PVS, RedPRL, and Twelf. These theorem provers may also be improved with math notation support.</p>
<h1 id="discussion">Discussion</h1>
<p>We evaluate this review by comparing it to other literature reviews.</p>
<p>It should first stand to say that this is the first living review on ITPs. As of such, this review already has many benefits over the current literature.</p>
<p>The clear improvement is this is the only review on ITPs that automatically updates to reflect the current state of the art. This means it can be referred back to at any time, and even used to track progress on efforts, such as formalizing mathematics.</p>
<p>Due to the availability of web technologies and interactivity, the living review is also much more accessible than a paper one. It allows readers to compare features of ITPs without scouring through large amounts of text or needing to pay large amounts of money to find them. The use of interactive tables and multiple pages in our review mean that the user can extract the knowledge that they are interested in without difficulty.</p>
<p>These benefits of the fact that it is living are great, but even without considering them, this review does build on past reviews.</p>
<p>This is the first review to ever classify the completed scope of ITPs. The classification helps people become aware of a module in their field.</p>
<p>A good place to start is to compare with the literature review we base some of our data on <span class="citation" data-cites="nawaz_survey_2019">[<a href="#ref-nawaz_survey_2019" role="doc-biblioref">63</a>]</span>. This review covers Theorem Provers in Formal Methods and what features they have. This literature review covers both Automatic Theorem Provers and Interactive Theorem Provers. For the sake of ITPs, the review has the scope of discovering what features each ITP has. This living review also includes all of the features and compares them. The living review also offers the benefits of being able to check the differences between mathematical libraries. Our contribution therefore, when considering ITPs and not Formal Methods in general, therefore contains a superset of the knowledge in this one. This is however expected, as we used this review as a basis for our one.</p>
<p>Other literature reviews include a survey on the field of Interactive Theorem Proving <span class="citation" data-cites="a_survey_of_itp">[<a href="#ref-a_survey_of_itp" role="doc-biblioref">56</a>]</span>. This review covers a brief history of ITPs, and a discussion of different calculi present in ITPs. This survey has a larger scope in terms of history, and detailed discussions of types of calculus and achievements. It however, is not systematic, and more represents an introduction to the field of ITPs, and may not be suitable for those currently in the field to understand the current state of the art. Furthermore, this review is difficult to understand without a strong knowledge of logic.</p>
<p>Finally, John Harrison completed a review of the history of ITPs <span class="citation" data-cites="history_of_itps">[<a href="#ref-history_of_itps" role="doc-biblioref">42</a>]</span>. As the title suggests, this review covers the history of ITPs, which is again outside the scope of this living review. This review is comprehensive in covering the development of ITPs up until 2014. However, at 7 years, it is currently out of date.</p>
<h2 id="limitations-with-current-work">Limitations with current work</h2>
<p>As much as this work does make progress on the current state of the field, it is not without limitations. This section covers possible limitations on this work, or items that were deemed out of scope but would be helpful.</p>
<p>One limitation of this work is that although it does represent a review of the field, the review would likely not be suitable as an introduction. Often, reviews allow users unfamiliar with a field to introduce themselves and better understand the topic so that they can make direct work. This review does not do this, and instead tracks the progress of the field, and may be more suitable to people within it.</p>
<p>A second limitation is that the author is not a mathematician by training, and there were a large number of modules that may require help from a professional mathematician to fully classify. Further, this review may contain errors in it due to the author not having training in the field. Living reviews can update over time however, and it is entirely possible that a mathematician could volunteer their time to complete the classification.</p>
<p>A third limitation is that although this is a living review, it does not often reference conference papers or journal articles, even though it possibly could. A more complete living review might include a discussion of the current trends in research, such as the usability research done on a particular theorem prover. We chose to exclude this from the current contribution due to requiring a large amount of manual work to keep up to date. However, we are convinced that such a review would be worth the effort in creating.</p>
<h2 id="future-work">Future Work</h2>
<p>During this investigation, several avenues of future work became clear.</p>
<p>Firstly, it was identified that the field of ITPs lacks empirical usability studies. Work in identifying and verifying usability issues with ITPs would do a good job to fill the gap in the literature. Many of the issues that arose in this review could be fantastic candidates.</p>
<p>Secondly, due to the nature of a living review, it is entirely possible to extend the scope over time. For instance, we considered the scope of libraries, counterexample generators and math provers. One possible extension of the review would be collecting large projects done in ITPs, in order to demonstrate their ability and usage in industry settings. This was outside the scope of this living review, but it could be updated in the future. This way a user from industry could consider whether they should invest in ITPs for their software project.</p>
<p>Finally, the author does hope that this may encourage the creation of more living reviews for other topics. A living review has many advantages, one of the most prominent being it is a considerably more accessible way of presenting information in a field, both to professionals and non professionals.</p>
<h2 id="summary">Summary</h2>
<p>ITPs are important due to their ability to assure very high levels of quality in software, which is only needed more as our reliance on technology only increases. However, ITPs have not yet had a large industry uptake, and it has been suggested <span class="citation" data-cites="kadoda_formal_1997">[<a href="#ref-kadoda_formal_1997" role="doc-biblioref">49</a>]</span> that usability issues with the ITPs could be the reason.</p>
<p>Motivated to investigate why a user might find the adoption of ITPs difficult, we performed a systematic literature review on usability issues mentioned in literature. We found there was a profound lack of empirical studies on usability about ITPs, and that there was a large number of potential usability problems that could be investigated.</p>
<p>From this systematic literature review, we decided to attempt to shed more light on these usability issues. We did this by creating a living review of ITPs. The review semi-automatically update periodically to reflect the current state of the field. This living review was designed with the intent of being accessible to newcomers, but also to ensure that it doesn’t become invalid years down the track.</p>
<p>In this living review, we examined the usability issues of small mathematical scopes, lack of counterexample generators and lack of math notation. We did this by systematically examining math modules created for ITPs, and classified them to the Mathematical Subject Classification. This allows readers to compare ITPs by the areas of mathematics that they cover, helping mathematicians make decisions about ITPs. Further, it tracks progress towards the formalization of different sections of mathematics.</p>
<p>We identified that some ITPs are currently better for different topics. Particularly depending on whether you want are looking to verify software or prove mathematical theorems. However, even if you wanted to prove mathematical theorems, different ITPs were better in different situations depending on the mathematical field.</p>
<p>We also directly examined the ITPs for counterexample generators and support for math notation, and included this within our living review.</p>
<p>This review will be updated periodically and therefore will remain a reference for the field.</p>
<h1 class="unnumbered" id="bibliography">Bibliography</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-Dijkstra" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">2008. Shortest paths. <em>Algorithms and data structures: The basic toolbox</em>. Springer Berlin Heidelberg. 191–215.</div>
</div>
<div id="ref-HOL_Zero" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Adams, M. 2010. Introducing HOL zero. <em>Mathematical software – ICMS 2010</em> (Berlin, Heidelberg, 2010), 142–143.</div>
</div>
<div id="ref-aitken_interactive_1998" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">Aitken, J.S., Gray, P., Melham, T. and Thomas, M. 1998. Interactive <span>Theorem</span> <span>Proving</span>: <span>An</span> <span>Empirical</span> <span>Study</span> of <span>User</span> <span>Activity</span>. <em>Journal of Symbolic Computation</em>. 25, 2 (1998), 263–284. DOI:https://doi.org/<a href="https://doi.org/10.1006/jsco.1997.0175">https://doi.org/10.1006/jsco.1997.0175</a>.</div>
</div>
<div id="ref-aitken_analysis_2000" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Aitken, S. and Melham, T. 2000. An analysis of errors in interactive proof attempts. <em>Interacting with Computers</em>. 12, 6 (2000), 565–586. DOI:https://doi.org/<a href="https://doi.org/10.1016/S0953-5438(99)00023-5">10.1016/S0953-5438(99)00023-5</a>.</div>
</div>
<div id="ref-RedPRL" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Angiuli, C., Cavallo, E., Hou (Favonia), K.-B., Harper, R. and Sterling, J. 2018. The RedPRL proof assistant (invited paper). <em><span class="nocase">Proceedings of the 13th International Workshop on</span> logical frameworks and meta-languages: Theory and practice, <span>Oxford, UK, 7th July 2018</span></em> (2018), 1–10.</div>
</div>
<div id="ref-asperti_considerations_2010" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">Asperti, A. and Coen, C.S. 2010. Some <span>Considerations</span> on the <span>Usability</span> of <span>Interactive</span> <span>Provers</span>. <em>Proceedings of the 10th <span>ASIC</span> and 9th <span>MKM</span> <span>International</span> <span>Conference</span>, and 17th <span>Calculemus</span> <span>Conference</span> on <span>Intelligent</span> <span>Computer</span> <span>Mathematics</span></em> (Berlin, Heidelberg, 2010), 147–156.</div>
</div>
<div id="ref-asperti_user_2007" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">Asperti, A., Sacerdoti Coen, C., Tassi, E. and Zacchiroli, S. 2007. User <span>Interaction</span> with the <span>Matita</span> <span>Proof</span> <span>Assistant</span>. <em>Journal of Automated Reasoning</em>. 39, 2 (Aug. 2007), 109–139. DOI:https://doi.org/<a href="https://doi.org/10.1007/s10817-007-9070-5">10.1007/s10817-007-9070-5</a>.</div>
</div>
<div id="ref-aspinall_towards_2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">Aspinall, D. and Kaliszyk, C. 2016. Towards <span>Formal</span> <span>Proof</span> <span>Metrics</span>. <em>Fundamental <span>Approaches</span> to <span>Software</span> <span>Engineering</span></em> (Berlin, Heidelberg, 2016), 325–341.</div>
</div>
<div id="ref-msc2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">Associate Editors of Mathematical Reviews and zbMATH 2020. MSC2020-mathematics subject classification system.</div>
</div>
<div id="ref-barras_asynchronous_2015" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">Barras, B., Tankink, C. and Tassi, E. 2015. Asynchronous <span>Processing</span> of <span>Coq</span> <span>Documents</span>: <span>From</span> the <span>Kernel</span> up to the <span>User</span> <span>Interface</span>. <em>Interactive <span>Theorem</span> <span>Proving</span></em> (Cham, 2015), 51–66.</div>
</div>
<div id="ref-CVC4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">Barrett, C., Conway, C.L., Deters, M., Hadarean, L., Jovanović, D., King, T., Reynolds, A. and Tinelli, C. 2011. CVC4. <em>Computer aided verification</em> (Berlin, Heidelberg, 2011), 171–177.</div>
</div>
<div id="ref-becker_lassie_2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">Becker, H., Bos, N., Gavran, I., Darulova, E. and Majumdar, R. 2021. Lassie: <span>HOL4</span> <span>Tactics</span> by <span>Example</span>. <em>Proceedings of the 10th <span>ACM</span> <span>SIGPLAN</span> <span>International</span> <span>Conference</span> on <span>Certified</span> <span>Programs</span> and <span>Proofs</span></em> (New York, NY, USA, 2021), 212–223.</div>
</div>
<div id="ref-beckert_evaluating_2012" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">Beckert, B. and Grebing, S. 2012. Evaluating the <span>Usability</span> of <span>Interactive</span> <span>Verification</span> <span>Systems</span>. <em><span>COMPARE</span></em> (2012).</div>
</div>
<div id="ref-beckert_interactive_2015" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">Beckert, B. and Grebing, S. 2015. Interactive <span>Theorem</span> <span>Proving</span> - <span>Modelling</span> the <span>User</span> in the <span>Proof</span> <span>Process</span>. <em>Bridging@<span>CADE</span></em> (2015).</div>
</div>
<div id="ref-beckert_usability_2015" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">Beckert, B., Grebing, S. and Böhl, F. 2015. A <span>Usability</span> <span>Evaluation</span> of <span>Interactive</span> <span>Theorem</span> <span>Provers</span> <span>Using</span> <span>Focus</span> <span>Groups</span>. <em>Software <span>Engineering</span> and <span>Formal</span> <span>Methods</span></em> (Cham, 2015), 3–19.</div>
</div>
<div id="ref-beckert_interaction_2017" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">Beckert, B., Grebing, S. and Ulbrich, M. 2017. An <span>Interaction</span> <span>Concept</span> for <span>Program</span> <span>Verification</span> <span>Systems</span> with <span>Explicit</span> <span>Proof</span> <span>Object</span>. <em>Hardware and <span>Software</span>: <span>Verification</span> and <span>Testing</span></em> (Cham, 2017), 163–178.</div>
</div>
<div id="ref-LEO-II" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">Benzmüller, C., Sultana, N., Paulson, L. and Theiss, F. 2015. The higher-order prover leo-II. <em>Journal of Automated Reasoning</em>. 55, (Dec. 2015). DOI:https://doi.org/<a href="https://doi.org/10.1007/s10817-015-9348-y">10.1007/s10817-015-9348-y</a>.</div>
</div>
<div id="ref-berman_development_2014" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">Berman, B.A. 2014. <em>Development and user testing of new user interfaces for mathematics and programming tools</em>. University of Iowa.</div>
</div>
<div id="ref-Coq" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">Bertot, Y. and Castéran, P. 2004. <em>Interactive theorem proving and program development: Coq’art: The calculus of inductive constructions</em>. Springer Berlin Heidelberg.</div>
</div>
<div id="ref-Nitpick" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">Blanchette, J.C. and Nipkow, T. 2010. Nitpick: A counterexample generator for higher-order logic based on a relational model finder. <em>Interactive theorem proving</em> (Berlin, Heidelberg, 2010), 131–146.</div>
</div>
<div id="ref-JAPE" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">Bornat, R. 2005. <em>Proof and disproof in formal logic: An introduction for programmers</em>. Oxford University Press.</div>
</div>
<div id="ref-bourke_challenges_2012" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">Bourke, T., Daum, M., Klein, G. and Kolanski, R. 2012. Challenges and <span>Experiences</span> in <span>Managing</span> <span>Large</span>-<span>Scale</span> <span>Proofs</span>. <em>Intelligent <span>Computer</span> <span>Mathematics</span></em> (Berlin, Heidelberg, 2012), 32–48.</div>
</div>
<div id="ref-QuickCheckIsabelle" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">Bulwahn, L. 2012. The new quickcheck for isabelle. <em>Certified programs and proofs</em> (Berlin, Heidelberg, 2012), 92–108.</div>
</div>
<div id="ref-QuickCheckHaskell" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">Claessen, K. and Hughes, J. 2000. QuickCheck: A lightweight tool for random testing of haskell programs. <em>SIGPLAN Not.</em> 35, 9 (Sep. 2000), 268–279. DOI:https://doi.org/<a href="https://doi.org/10.1145/357766.351266">10.1145/357766.351266</a>.</div>
</div>
<div id="ref-Atelier_B" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">Clearsy The industrial tool to efficiently deploy the b method - atelier b.</div>
</div>
<div id="ref-NanchakuCoq" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">Cruanes, S. and Blanchette, J. 2016. Extending nunchaku to dependent type theory. <em>Electronic Proceedings in Theoretical Computer Science</em>. 210, (Jun. 2016), 3–12. DOI:https://doi.org/<a href="https://doi.org/10.4204/EPTCS.210.3">10.4204/EPTCS.210.3</a>.</div>
</div>
<div id="ref-Elm" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">Czaplicki, E. Elm book.</div>
</div>
<div id="ref-QuickChick" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">Dénès, M. and Pierce, B.C. 2014. QuickChick: Property-based testing for coq. (2014).</div>
</div>
<div id="ref-QuickCheckAgda" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">Dybjer, P., Haiyan, Q. and Takeyama, M. 2003. Combining testing and proving in dependent type theory. <em>Theorem proving in higher order logics</em> (Berlin, Heidelberg, 2003), 188–203.</div>
</div>
<div id="ref-eastaughffe_support_1998" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[30] </div><div class="csl-right-inline">Eastaughffe, K. 1998. Support for <span>Interactive</span> <span>Theorem</span> <span>Proving</span>: <span>Some</span> <span>Design</span> <span>Principles</span> and <span>Their</span> <span>Application</span>. (1998).</div>
</div>
<div id="ref-DoubleCheck" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[31] </div><div class="csl-right-inline">Eastlund, C. 2009. DoubleCheck your theorems. <em>Proceedings of the eighth international workshop on the ACL2 theorem prover and its applications</em> (New York, NY, USA, 2009), 42–46.</div>
</div>
<div id="ref-Four_Color" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">G. Gonthier 2008. <span class="nocase">Formal proof of the Four-Color theorem</span>. <em><span>Notices of the American Mathematical Society</span></em>.</div>
</div>
<div id="ref-Getfol" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[33] </div><div class="csl-right-inline">Giunchiglia, F. and Cimatti, A. 1994. Introspective metatheoretic reasoning. <em>Logic program synthesis and transformation — meta-programming in logic</em> (Berlin, Heidelberg, 1994), 425–439.</div>
</div>
<div id="ref-Mizar" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[34] </div><div class="csl-right-inline">Grabowski, A., Kornilowicz, A. and Naumowicz, A. 2010. Mizar in a nutshell. <em>Journal of Formalized Reasoning</em>. 3, 2 (2010), 153–245. DOI:https://doi.org/<a href="https://doi.org/10.6092/issn.1972-5787/1980">10.6092/issn.1972-5787/1980</a>.</div>
</div>
<div id="ref-grebing_seamless_2020" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[35] </div><div class="csl-right-inline">Grebing, S., Klamroth, J. and Ulbrich, M. 2020. Seamless <span>Interactive</span> <span>Program</span> <span>Verification</span>. <em>Verified <span>Software</span>. <span>Theories</span>, <span>Tools</span>, and <span>Experiments</span></em> (Cham, 2020), 68–86.</div>
</div>
<div id="ref-grebing_usability_2020" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[36] </div><div class="csl-right-inline">Grebing, S. and Ulbrich, M. 2020. Usability <span>Recommendations</span> for <span>User</span> <span>Guidance</span> in <span>Deductive</span> <span>Program</span> <span>Verification</span>. <em>Deductive <span>Software</span> <span>Verification</span>: <span>Future</span> <span>Perspectives</span>: <span>Reflections</span> on the <span>Occasion</span> of 20 <span>Years</span> of <span>KeY</span></em>. W. Ahrendt, B. Beckert, R. Bubel, R. Hähnle, and M. Ulbrich, eds. Springer International Publishing. 261–284.</div>
</div>
<div id="ref-green_usability_1996" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[37] </div><div class="csl-right-inline">Green, T.R.G. and Petre, M. 1996. Usability <span>Analysis</span> of <span>Visual</span> <span>Programming</span> <span>Environments</span>: <span>A</span> <span>‘<span>Cognitive</span> <span>Dimensions</span>’</span> <span>Framework</span>. <em>Journal of Visual Languages &amp; Computing</em>. 7, 2 (1996), 131–174.</div>
</div>
<div id="ref-grov_tinker_2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[38] </div><div class="csl-right-inline">Grov, G. and Lin, Y. 2018. The <span>Tinker</span> tool for graphical tactic development. <em>International Journal on Software Tools for Technology Transfer</em>. 20, 2 (Apr. 2018), 139–155. DOI:https://doi.org/<a href="https://doi.org/10.1007/s10009-017-0452-7">10.1007/s10009-017-0452-7</a>.</div>
</div>
<div id="ref-hahnle_deductive_2019" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[39] </div><div class="csl-right-inline">Hähnle, R. and Huisman, M. 2019. Deductive <span>Software</span> <span>Verification</span>: <span>From</span> <span>Pen</span>-and-<span>Paper</span> <span>Proofs</span> to <span>Industrial</span> <span>Tools</span>. <em>Computing and <span>Software</span> <span>Science</span>: <span>State</span> of the <span>Art</span> and <span>Perspectives</span></em>. B. Steffen and G. Woeginger, eds. Springer International Publishing. 345–373.</div>
</div>
<div id="ref-Flyspeck" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[40] </div><div class="csl-right-inline">HALES, T., ADAMS, M., BAUER, G., DANG, T.D., HARRISON, J., HOANG, L.T., KALISZYK, C., MAGRON, V., MCLAUGHLIN, S., NGUYEN, T.T. and al., et 2017. A FORMAL PROOF OF THE KEPLER CONJECTURE. <em>Forum of Mathematics, Pi</em>. 5, (2017), e2. DOI:https://doi.org/<a href="https://doi.org/10.1017/fmp.2017.1">10.1017/fmp.2017.1</a>.</div>
</div>
<div id="ref-HOL_Light" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[41] </div><div class="csl-right-inline">Harrison, J. 2009. HOL light: An overview. <em>Theorem proving in higher order logics</em> (Berlin, Heidelberg, 2009), 60–66.</div>
</div>
<div id="ref-history_of_itps" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[42] </div><div class="csl-right-inline">Harrison, J., Urban, J. and Wiedijk, F. 2014. History of interactive theorem proving. <em>Handbook of the History of Logic</em>. 135–214.</div>
</div>
<div id="ref-hentschel_integrating_2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[43] </div><div class="csl-right-inline">Hentschel, M. 2016. <em>Integrating <span>Symbolic</span> <span>Execution</span>, <span>Debugging</span> and <span>Verification</span></em>. Technische Universität Darmstadt.</div>
</div>
<div id="ref-hentschel_empirical_2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[44] </div><div class="csl-right-inline">Hentschel, M., Hähnle, R. and Bubel, R. 2016. An <span>Empirical</span> <span>Evaluation</span> of <span>Two</span> <span>User</span> <span>Interfaces</span> of an <span>Interactive</span> <span>Program</span> <span>Verifier</span>. <em>Proceedings of the 31st <span>IEEE</span>/<span>ACM</span> <span>International</span> <span>Conference</span> on <span>Automated</span> <span>Software</span> <span>Engineering</span></em> (New York, NY, USA, 2016), 403–413.</div>
</div>
<div id="ref-hentschel_interactive_2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[45] </div><div class="csl-right-inline">Hentschel, M., Hähnle, R. and Bubel, R. 2016. The <span>Interactive</span> <span>Verification</span> <span>Debugger</span>: <span>Effective</span> <span>Understanding</span> of <span>Interactive</span> <span>Proof</span> <span>Attempts</span>. <em>Proceedings of the 31st <span>IEEE</span>/<span>ACM</span> <span>International</span> <span>Conference</span> on <span>Automated</span> <span>Software</span> <span>Engineering</span></em> (New York, NY, USA, 2016), 846–851.</div>
</div>
<div id="ref-hunter_agent-based_2005" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[46] </div><div class="csl-right-inline">Hunter, C., Robinson, P. and Strooper, P. 2005. Agent-<span>Based</span> <span>Distributed</span> <span>Software</span> <span>Verification</span>. <em>Proceedings of the <span>Twenty</span>-<span>Eighth</span> <span>Australasian</span> <span>Conference</span> on <span>Computer</span> <span>Science</span> - <span>Volume</span> 38</em> (AUS, 2005), 159–164.</div>
</div>
<div id="ref-HACL" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[47] </div><div class="csl-right-inline">Jean Karim Zinzindohoué, J.P., Karthikeyan Bhargavan 2017. <em><span>HACL</span>*: <span>A</span> <span>Verified</span> <span>Modern</span> <span>Cryptographic</span> <span>Library</span></em>.</div>
</div>
<div id="ref-kadoda_cognitive_2000" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[48] </div><div class="csl-right-inline">Kadoda, G. 2000. <em>A <span>Cognitive</span> <span>Dimensions</span> view of the differences between designers and users of theorem proving assistants</em>.</div>
</div>
<div id="ref-kadoda_formal_1997" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[49] </div><div class="csl-right-inline">Kadoda, G.F. 1997. <em>Formal software development tools: An investigation into usability</em>.</div>
</div>
<div id="ref-kadoda_desirable_1999" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[50] </div><div class="csl-right-inline">Kadoda, G.F., Stone, R. and Diaper, D. 1999. Desirable features of educational theorem provers - a cognitive dimensions viewpoint. <em><span>PPIG</span></em> (1999).</div>
</div>
<div id="ref-ACL2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[51] </div><div class="csl-right-inline">Kaufmann, M., Manolios, P. and Moore, J.S. 2000. <em>Computer-aided reasoning: An approach</em>. Springer US.</div>
</div>
<div id="ref-kawabata_traf_2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[52] </div><div class="csl-right-inline">Kawabata, H., Tanaka, Y., Kimura, M. and Hironaka, T. 2018. Traf: <span>A</span> <span>Graphical</span> <span>Proof</span> <span>Tree</span> <span>Viewer</span> <span>Cooperating</span> with <span>Coq</span> <span>Through</span> <span>Proof</span> <span>General</span>. <em>Programming <span>Languages</span> and <span>Systems</span></em> (Cham, 2018), 157–165.</div>
</div>
<div id="ref-Sel4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[53] </div><div class="csl-right-inline">Klein, G., Elphinstone, K., Heiser, G., Andronick, J., Cock, D., Derrin, P., Elkaduwe, D., Engelhardt, K., Kolanski, R., Norrish, M., Sewell, T., Tuch, H. and Winwood, S. 2009. <span>SeL4</span>: <span>Formal</span> <span>Verification</span> of an <span>OS</span> <span>Kernel</span>. <em>Proceedings of the <span>ACM</span> <span>SIGOPS</span> 22nd <span>Symposium</span> on <span>Operating</span> <span>Systems</span> <span>Principles</span></em> (New York, NY, USA, 2009), 207–220.</div>
</div>
<div id="ref-CompCert" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[54] </div><div class="csl-right-inline">Leroy, X. 2009. Formal verification of a realistic compiler. <em>Communications of the ACM</em>. 52, 7 (2009), 107–115.</div>
</div>
<div id="ref-lin_understanding_2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[55] </div><div class="csl-right-inline">Lin, Y., Grov, G. and Arthan, R. 2016. Understanding and maintaining tactics graphically <span>OR</span> how we are learning that a diagram can be worth more than <span>10K</span> <span>LoC</span>. <em>Journal of Formalized Reasoning</em>. 9, 2 (Dec. 2016), 69–130. DOI:https://doi.org/<a href="https://doi.org/10.6092/issn.1972-5787/6298">10.6092/issn.1972-5787/6298</a>.</div>
</div>
<div id="ref-a_survey_of_itp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[56] </div><div class="csl-right-inline">Marić, F. 2015. A survey of interactive theorem proving. <em>Zbornik radova</em>. (Jul. 2015).</div>
</div>
<div id="ref-Rust" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[57] </div><div class="csl-right-inline">Matsakis, N.D. and Klock, F.S. 2014. The <span>Rust</span> <span>Language</span>. <em>Proceedings of the 2014 <span>ACM</span> <span>SIGAda</span> <span>Annual</span> <span>Conference</span> on <span>High</span> <span>Integrity</span> <span>Language</span> <span>Technology</span></em> (New York, NY, USA, 2014), 103–104.</div>
</div>
<div id="ref-CodeComplete" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[58] </div><div class="csl-right-inline">McConnell, S. 2004. <em>Code <span>Complete</span>, <span>Second</span> <span>Edition</span></em>. Microsoft Press.</div>
</div>
<div id="ref-mitsch_keymaera_2017" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[59] </div><div class="csl-right-inline">Mitsch, S. and Platzer, A. 2017. The <span>KeYmaera</span> <span>X</span> <span>Proof</span> <span>IDE</span> - <span>Concepts</span> on <span>Usability</span> in <span>Hybrid</span> <span>Systems</span> <span>Theorem</span> <span>Proving</span>. <em>Electronic Proceedings in Theoretical Computer Science</em>. 240, (Jan. 2017), 67–81. DOI:https://doi.org/<a href="https://doi.org/10.4204/eptcs.240.5">10.4204/eptcs.240.5</a>.</div>
</div>
<div id="ref-DijkstraACL2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[60] </div><div class="csl-right-inline">Moore, J.S. and Zhang, Q. 2005. Proof pearl: Dijkstra’s shortest path algorithm verified with ACL2. <em>Theorem proving in higher order logics</em> (Berlin, Heidelberg, 2005), 373–384.</div>
</div>
<div id="ref-Lean" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[61] </div><div class="csl-right-inline">Moura, L. de, Kong, S., Avigad, J., Doorn, F. van and Raumer, J. von 2015. The <span>Lean</span> <span>Theorem</span> <span>Prover</span> (<span>System</span> <span>Description</span>). <em>Automated <span>Deduction</span> - <span>CADE</span>-25</em> (Cham, 2015), 378–388.</div>
</div>
<div id="ref-nagashima_pamper_2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[62] </div><div class="csl-right-inline">Nagashima, Y. and He, Y. 2018. <span>PaMpeR</span>: <span>Proof</span> <span>Method</span> <span>Recommendation</span> <span>System</span> for <span>Isabelle</span>/<span>HOL</span>. <em>Proceedings of the 33rd <span>ACM</span>/<span>IEEE</span> <span>International</span> <span>Conference</span> on <span>Automated</span> <span>Software</span> <span>Engineering</span></em> (New York, NY, USA, 2018), 362–372.</div>
</div>
<div id="ref-nawaz_survey_2019" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[63] </div><div class="csl-right-inline">Nawaz, M.S., Malik, M., Li, Y., Sun, M. and Lali, M.I.U. 2019. A <span>Survey</span> on <span>Theorem</span> <span>Provers</span> in <span>Formal</span> <span>Methods</span>. (2019).</div>
</div>
<div id="ref-Agda" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[64] </div><div class="csl-right-inline">Norell, U. 2009. Dependently typed programming in agda. <em>Proceedings of the 4th international workshop on types in language design and implementation</em> (New York, NY, USA, 2009), 1–2.</div>
</div>
<div id="ref-Metamath" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[65] </div><div class="csl-right-inline">Norman Megill 2007. <em><span class="nocase">Metamath: A Computer Language for Pure Mathematics</span></em>. <span>Lulu Press USA</span>.</div>
</div>
<div id="ref-PVSQuickCheck" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[66] </div><div class="csl-right-inline">Owre, S. 2006. Random testing in PVS. (2006).</div>
</div>
<div id="ref-NanchakuLean" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[67] </div><div class="csl-right-inline">Pablo Le Hénaff <span class="nocase">nunchaku-lean · GitLab</span>.</div>
</div>
<div id="ref-Isabelle" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[68] </div><div class="csl-right-inline">Paulson, L.C. ed. 1994. <em>Isabelle: A generic theorem prover</em>. Springer Berlin Heidelberg.</div>
</div>
<div id="ref-Twelf" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[69] </div><div class="csl-right-inline">Pfenning, F. and Schuermann, C. 2002. <span class="nocase">Twelf’s User Guide</span>.</div>
</div>
<div id="ref-ProofPower" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[70] </div><div class="csl-right-inline">R. Arthan 2005. <span class="nocase">ProofPower–SLRP user guide. Technical report</span>. <em><span>Lemma 1 Limited</span></em>.</div>
</div>
<div id="ref-ringer_replica_2020" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[71] </div><div class="csl-right-inline">Ringer, T., Sanchez-Stern, A., Grossman, D. and Lerner, S. 2020. <span>REPLica</span>: <span>REPL</span> <span>Instrumentation</span> for <span>Coq</span> <span>Analysis</span>. <em>Proceedings of the 9th <span>ACM</span> <span>SIGPLAN</span> <span>International</span> <span>Conference</span> on <span>Certified</span> <span>Programs</span> and <span>Proofs</span></em> (New York, NY, USA, 2020), 99–113.</div>
</div>
<div id="ref-roe_coqpie_2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[72] </div><div class="csl-right-inline">Roe, K. and Smith, S. 2016. <span>CoqPIE</span>: <span>An</span> <span>IDE</span> <span>Aimed</span> at <span>Improving</span> <span>Proof</span> <span>Development</span> <span>Productivity</span>. <em>Interactive <span>Theorem</span> <span>Proving</span></em> (Cham, 2016), 491–499.</div>
</div>
<div id="ref-PVS" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[73] </div><div class="csl-right-inline">Rushby, J. 2006. Tutorial: Automated formal methods with PVS, SAL, and yices. <em>Fourth IEEE international conference on software engineering and formal methods (SEFM’06)</em> (2006), 262–262.</div>
</div>
<div id="ref-Z/EVES" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[74] </div><div class="csl-right-inline">Saaltink, M. 1997. The z/EVES system. <em>ZUM ’97: The z formal specification notation</em> (Berlin, Heidelberg, 1997), 72–85.</div>
</div>
<div id="ref-Vega-Lite" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[75] </div><div class="csl-right-inline">Satyanarayan, A., Moritz, D., Wongsuphasawat, K. and Heer, J. 2017. Vega-lite: A grammar of interactive graphics. <em>IEEE Transactions on Visualization and Computer Graphics</em>. 23, 1 (Jan. 2017), 341–350. DOI:https://doi.org/<a href="https://doi.org/10.1109/TVCG.2016.2599030">10.1109/TVCG.2016.2599030</a>.</div>
</div>
<div id="ref-shams_accessible_2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[76] </div><div class="csl-right-inline">Shams, Z., Sato, Y., Jamnik, M. and Stapleton, G. 2018. Accessible <span>Reasoning</span> with <span>Diagrams</span>: <span>From</span> <span>Cognition</span> to <span>Automation</span>. <em>Diagrammatic <span>Representation</span> and <span>Inference</span></em> (Cham, 2018), 247–263.</div>
</div>
<div id="ref-CertifiedSoftware" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[77] </div><div class="csl-right-inline">Shao, Z. 2010. Certified software. <em>Commun. ACM</em>. 53, 12 (Dec. 2010), 56–66. DOI:https://doi.org/<a href="https://doi.org/10.1145/1859204.1859226">10.1145/1859204.1859226</a>.</div>
</div>
<div id="ref-HOL4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[78] </div><div class="csl-right-inline">Slind, K. and Norrish, M. 2008. A brief overview of HOL4. <em>Proceedings of the 21st international conference on theorem proving in higher order logics</em> (Berlin, Heidelberg, 2008), 28–32.</div>
</div>
<div id="ref-spichkova_human-centred_2017" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[79] </div><div class="csl-right-inline">Spichkova, M. and Simic, M. 2017. Human-centred analysis of the dependencies within sets of proofs. <em>Knowledge-Based and Intelligent Information &amp; Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France</em>. 112, (Jan. 2017), 2290–2298. DOI:https://doi.org/<a href="https://doi.org/10.1016/j.procs.2017.08.256">10.1016/j.procs.2017.08.256</a>.</div>
</div>
<div id="ref-tassi_interactive_2008" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[80] </div><div class="csl-right-inline">Tassi, E. 2008. <em>Interactive theorem provers: Issues faced as a user and tackled as a developer</em>. alma.</div>
</div>
<div id="ref-KodKod" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[81] </div><div class="csl-right-inline">Torlak, E. and Jackson, D. 2007. Kodkod: A relational model finder. <em>Tools and algorithms for the construction and analysis of systems</em> (Berlin, Heidelberg, 2007), 632–647.</div>
</div>
<div id="ref-wenzel_asynchronous_2014" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[82] </div><div class="csl-right-inline">Wenzel, M. 2014. Asynchronous <span>User</span> <span>Interaction</span> and <span>Tool</span> <span>Integration</span> in <span>Isabelle</span>/<span>PIDE</span>. <em>Interactive <span>Theorem</span> <span>Proving</span></em> (Cham, 2014), 515–530.</div>
</div>
<div id="ref-wenzel_isabelle_2011" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[83] </div><div class="csl-right-inline">Wenzel, M. 2011. Isabelle as <span>Document</span>-<span>Oriented</span> <span>Proof</span> <span>Assistant</span>. <em>Intelligent <span>Computer</span> <span>Mathematics</span></em> (Berlin, Heidelberg, 2011), 244–259.</div>
</div>
<div id="ref-wenzel_structured_2006" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[84] </div><div class="csl-right-inline">Wenzel, M. 2006. Structured <span>Induction</span> <span>Proofs</span> in <span>Isabelle</span>/<span>Isar</span>. <em>Mathematical <span>Knowledge</span> <span>Management</span></em> (Berlin, Heidelberg, 2006), 17–30.</div>
</div>
<div id="ref-QED_Manifesto" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[85] </div><div class="csl-right-inline">Wiedijk, F. 2007. The QED manifesto revisited. (2007).</div>
</div>
<div id="ref-Snowballing" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[86] </div><div class="csl-right-inline">Wohlin, C. 2014. Guidelines for snowballing in systematic literature studies and a replication in software engineering. <em>Proceedings of the 18th international conference on evaluation and assessment in software engineering</em> (New York, NY, USA, 2014).</div>
</div>
<div id="ref-zacchiroli_user_2007" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[87] </div><div class="csl-right-inline">Zacchiroli, S. 2007. <em>User interaction widgets for interactive theorem proving</em>. alma.</div>
</div>
</div>
</body>
</html>
